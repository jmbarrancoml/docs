---
title: "Agent reasoning and planning"
description: "Deep dive into agent reasoning systems and planning algorithms, including symbolic reasoning, probabilistic inference, automated planning, and goal-oriented decision making for autonomous AI agents."
---

# Agent reasoning and planning

Reasoning and planning form the cognitive core of intelligent agents, enabling them to understand complex situations, make informed decisions, and pursue long-term goals. This comprehensive guide explores the algorithms, frameworks, and techniques that power agent intelligence.

## Understanding agent reasoning

### Cognitive architectures for reasoning

Agent reasoning systems require sophisticated architectures to handle different types of cognitive processes:

```python
import numpy as np
from typing import Dict, List, Optional, Any, Callable, Tuple, Set, Union
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from enum import Enum
import heapq
import json
import time
from collections import defaultdict, deque

class ReasoningType(Enum):
    DEDUCTIVE = "deductive"
    INDUCTIVE = "inductive" 
    ABDUCTIVE = "abductive"
    ANALOGICAL = "analogical"
    CAUSAL = "causal"
    PROBABILISTIC = "probabilistic"
    TEMPORAL = "temporal"

class KnowledgeType(Enum):
    FACTUAL = "factual"
    PROCEDURAL = "procedural"
    EPISODIC = "episodic"
    SEMANTIC = "semantic"
    CAUSAL = "causal"
    TEMPORAL = "temporal"

@dataclass
class Belief:
    """Represents a belief in the agent's knowledge base"""
    content: Any
    confidence: float
    source: str
    timestamp: float
    evidence: List[str] = field(default_factory=list)
    knowledge_type: KnowledgeType = KnowledgeType.FACTUAL
    
@dataclass
class Fact:
    """Represents a fact in the knowledge base"""
    predicate: str
    arguments: List[str]
    truth_value: bool = True
    confidence: float = 1.0
    
@dataclass
class Rule:
    """Represents an inference rule"""
    premises: List[Fact]
    conclusion: Fact
    rule_type: str
    confidence: float = 1.0

class ReasoningEngine(ABC):
    """Abstract base class for reasoning engines"""
    
    def __init__(self, name: str):
        self.name = name
        self.knowledge_base = {}
        self.beliefs = []
        self.inference_rules = []
        
    @abstractmethod
    def reason(self, query: Any, context: Dict[str, Any] = None) -> Any:
        """Perform reasoning on the given query"""
        pass
    
    def add_belief(self, belief: Belief):
        """Add a belief to the knowledge base"""
        self.beliefs.append(belief)
        
    def add_rule(self, rule: Rule):
        """Add an inference rule"""
        self.inference_rules.append(rule)
        
    def get_relevant_beliefs(self, query: Any) -> List[Belief]:
        """Get beliefs relevant to the query"""
        relevant = []
        query_str = str(query).lower()
        
        for belief in self.beliefs:
            if query_str in str(belief.content).lower():
                relevant.append(belief)
        
        return relevant

class SymbolicReasoner(ReasoningEngine):
    """Symbolic reasoning engine using logical inference"""
    
    def __init__(self, name: str = "SymbolicReasoner"):
        super().__init__(name)
        self.working_memory = []
        self.goal_stack = []
        
    def reason(self, query: Any, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Perform symbolic reasoning"""
        
        # Convert query to logical form
        logical_query = self._parse_query(query)
        
        # Forward chaining inference
        forward_results = self._forward_chaining(logical_query)
        
        # Backward chaining for goal-directed reasoning
        backward_results = self._backward_chaining(logical_query)
        
        # Combine results
        reasoning_result = {
            'query': query,
            'logical_form': logical_query,
            'forward_inference': forward_results,
            'backward_inference': backward_results,
            'conclusion': self._synthesize_conclusions(forward_results, backward_results),
            'confidence': self._calculate_reasoning_confidence(forward_results, backward_results)
        }
        
        return reasoning_result
    
    def _parse_query(self, query: Any) -> Dict[str, Any]:
        """Parse natural language query into logical form"""
        # Simplified parsing - in practice would use NLP
        
        query_str = str(query).lower()
        
        # Identify predicates and arguments
        predicates = []
        if 'is' in query_str:
            parts = query_str.split(' is ')
            if len(parts) == 2:
                predicates.append(Fact('is', [parts[0].strip(), parts[1].strip()]))
        
        if 'can' in query_str:
            parts = query_str.split(' can ')
            if len(parts) == 2:
                predicates.append(Fact('can', [parts[0].strip(), parts[1].strip()]))
        
        return {
            'original': query,
            'predicates': predicates,
            'variables': self._extract_variables(query_str),
            'query_type': self._classify_query(query_str)
        }
    
    def _forward_chaining(self, logical_query: Dict[str, Any]) -> Dict[str, Any]:
        """Forward chaining inference"""
        
        derived_facts = set()
        new_facts = True
        iterations = 0
        max_iterations = 100
        
        # Start with known facts
        known_facts = {self._fact_to_string(fact) for belief in self.beliefs 
                      if hasattr(belief.content, '__dict__') 
                      for fact in [belief.content] if isinstance(belief.content, Fact)}
        
        while new_facts and iterations < max_iterations:
            new_facts = False
            iterations += 1
            
            for rule in self.inference_rules:
                # Check if all premises are satisfied
                premises_satisfied = all(
                    self._fact_to_string(premise) in known_facts or 
                    self._fact_to_string(premise) in derived_facts
                    for premise in rule.premises
                )
                
                if premises_satisfied:
                    conclusion_str = self._fact_to_string(rule.conclusion)
                    if conclusion_str not in known_facts and conclusion_str not in derived_facts:
                        derived_facts.add(conclusion_str)
                        new_facts = True
        
        return {
            'derived_facts': list(derived_facts),
            'iterations': iterations,
            'inference_chain': self._build_inference_chain(derived_facts)
        }
    
    def _backward_chaining(self, logical_query: Dict[str, Any]) -> Dict[str, Any]:
        """Backward chaining for goal-directed reasoning"""
        
        goals = logical_query.get('predicates', [])
        proof_tree = {}
        
        for goal in goals:
            goal_str = self._fact_to_string(goal)
            proof_tree[goal_str] = self._prove_goal(goal)
        
        return {
            'goals': [self._fact_to_string(g) for g in goals],
            'proof_tree': proof_tree,
            'provable': all(proof_tree.values())
        }
    
    def _prove_goal(self, goal: Fact) -> bool:
        """Attempt to prove a goal using backward chaining"""
        
        goal_str = self._fact_to_string(goal)
        
        # Check if goal is already known
        for belief in self.beliefs:
            if isinstance(belief.content, Fact) and self._fact_to_string(belief.content) == goal_str:
                return True
        
        # Try to prove using rules
        for rule in self.inference_rules:
            if self._fact_to_string(rule.conclusion) == goal_str:
                # Try to prove all premises
                all_premises_proven = all(self._prove_goal(premise) for premise in rule.premises)
                if all_premises_proven:
                    return True
        
        return False
    
    def _fact_to_string(self, fact: Fact) -> str:
        """Convert fact to string representation"""
        return f"{fact.predicate}({', '.join(fact.arguments)})"
    
    def _extract_variables(self, query: str) -> List[str]:
        """Extract variables from query"""
        # Simple variable extraction - would be more sophisticated in practice
        variables = []
        words = query.split()
        
        for word in words:
            if word.isupper() or word.startswith('?'):
                variables.append(word)
        
        return variables
    
    def _classify_query(self, query: str) -> str:
        """Classify the type of query"""
        if '?' in query:
            return 'question'
        elif 'if' in query:
            return 'conditional'
        elif 'why' in query:
            return 'explanation'
        else:
            return 'assertion'
    
    def _synthesize_conclusions(self, forward: Dict, backward: Dict) -> List[str]:
        """Synthesize conclusions from forward and backward inference"""
        conclusions = []
        
        # Add derived facts from forward chaining
        conclusions.extend(forward.get('derived_facts', []))
        
        # Add provable goals from backward chaining
        for goal, provable in backward.get('proof_tree', {}).items():
            if provable:
                conclusions.append(f"Proven: {goal}")
        
        return conclusions
    
    def _calculate_reasoning_confidence(self, forward: Dict, backward: Dict) -> float:
        """Calculate confidence in reasoning results"""
        
        forward_confidence = 0.8 if forward.get('derived_facts') else 0.5
        backward_confidence = 0.9 if backward.get('provable', False) else 0.3
        
        return (forward_confidence + backward_confidence) / 2
    
    def _build_inference_chain(self, derived_facts: Set[str]) -> List[Dict]:
        """Build chain showing how facts were derived"""
        # Simplified implementation
        return [{'fact': fact, 'rule': 'inference_rule'} for fact in derived_facts]

class ProbabilisticReasoner(ReasoningEngine):
    """Probabilistic reasoning engine using Bayesian inference"""
    
    def __init__(self, name: str = "ProbabilisticReasoner"):
        super().__init__(name)
        self.probability_network = {}
        self.conditional_probabilities = {}
        
    def reason(self, query: Any, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Perform probabilistic reasoning"""
        
        # Parse query to extract probabilistic statements
        prob_query = self._parse_probabilistic_query(query)
        
        # Bayesian inference
        posterior_probabilities = self._bayesian_inference(prob_query)
        
        # Causal reasoning if applicable
        causal_analysis = self._causal_reasoning(prob_query)
        
        return {
            'query': query,
            'probabilistic_form': prob_query,
            'posterior_probabilities': posterior_probabilities,
            'causal_analysis': causal_analysis,
            'uncertainty': self._calculate_uncertainty(posterior_probabilities),
            'confidence_intervals': self._calculate_confidence_intervals(posterior_probabilities)
        }
    
    def _parse_probabilistic_query(self, query: Any) -> Dict[str, Any]:
        """Parse query for probabilistic elements"""
        query_str = str(query).lower()
        
        variables = self._extract_random_variables(query_str)
        evidence = self._extract_evidence(query_str)
        target = self._extract_target_variable(query_str)
        
        return {
            'variables': variables,
            'evidence': evidence,
            'target': target,
            'query_type': self._classify_probabilistic_query(query_str)
        }
    
    def _bayesian_inference(self, prob_query: Dict[str, Any]) -> Dict[str, float]:
        """Perform Bayesian inference"""
        
        target = prob_query.get('target')
        evidence = prob_query.get('evidence', {})
        
        if not target:
            return {}
        
        # Mock Bayesian computation - would use proper probabilistic inference
        prior = self._get_prior_probability(target)
        likelihood = self._calculate_likelihood(target, evidence)
        marginal = self._calculate_marginal_probability(evidence)
        
        if marginal > 0:
            posterior = (prior * likelihood) / marginal
        else:
            posterior = prior
        
        return {
            'prior': prior,
            'likelihood': likelihood,
            'marginal': marginal,
            'posterior': posterior
        }
    
    def _causal_reasoning(self, prob_query: Dict[str, Any]) -> Dict[str, Any]:
        """Perform causal reasoning"""
        
        variables = prob_query.get('variables', [])
        
        if len(variables) < 2:
            return {'causal_relationships': []}
        
        # Mock causal analysis
        causal_relationships = []
        for i in range(len(variables) - 1):
            cause = variables[i]
            effect = variables[i + 1]
            
            # Calculate causal strength (mock)
            causal_strength = np.random.uniform(0.1, 0.9)
            
            causal_relationships.append({
                'cause': cause,
                'effect': effect,
                'strength': causal_strength,
                'type': 'direct' if causal_strength > 0.7 else 'indirect'
            })
        
        return {
            'causal_relationships': causal_relationships,
            'causal_graph': self._build_causal_graph(causal_relationships)
        }
    
    def _extract_random_variables(self, query: str) -> List[str]:
        """Extract random variables from query"""
        # Simplified extraction
        words = query.split()
        variables = []
        
        for word in words:
            if word.endswith('?') or word in ['probability', 'chance', 'likely']:
                continue
            if len(word) > 2 and word.isalpha():
                variables.append(word)
        
        return variables[:3]  # Limit to 3 variables for simplicity
    
    def _extract_evidence(self, query: str) -> Dict[str, Any]:
        """Extract evidence from query"""
        evidence = {}
        
        if 'given' in query:
            parts = query.split('given')
            if len(parts) > 1:
                evidence_text = parts[1].strip()
                # Simple evidence parsing
                if '=' in evidence_text:
                    key, value = evidence_text.split('=', 1)
                    evidence[key.strip()] = value.strip()
        
        return evidence
    
    def _extract_target_variable(self, query: str) -> Optional[str]:
        """Extract target variable for inference"""
        if 'probability of' in query:
            start = query.find('probability of') + len('probability of')
            end = query.find(' ', start)
            if end == -1:
                end = len(query)
            return query[start:end].strip()
        
        return None
    
    def _get_prior_probability(self, variable: str) -> float:
        """Get prior probability for variable"""
        # Mock prior - would lookup in knowledge base
        return np.random.uniform(0.1, 0.9)
    
    def _calculate_likelihood(self, target: str, evidence: Dict[str, Any]) -> float:
        """Calculate likelihood given evidence"""
        # Mock likelihood calculation
        base_likelihood = 0.5
        
        for key, value in evidence.items():
            # Adjust likelihood based on evidence
            if str(value).lower() in ['true', 'yes', '1']:
                base_likelihood += 0.2
            else:
                base_likelihood -= 0.1
        
        return max(0.01, min(0.99, base_likelihood))
    
    def _calculate_marginal_probability(self, evidence: Dict[str, Any]) -> float:
        """Calculate marginal probability of evidence"""
        # Mock marginal calculation
        if not evidence:
            return 1.0
        
        return np.random.uniform(0.1, 0.8)
    
    def _calculate_uncertainty(self, probabilities: Dict[str, float]) -> float:
        """Calculate uncertainty in probabilistic reasoning"""
        posterior = probabilities.get('posterior', 0.5)
        
        # Entropy-based uncertainty
        if posterior == 0 or posterior == 1:
            return 0.0
        
        entropy = -(posterior * np.log2(posterior) + (1 - posterior) * np.log2(1 - posterior))
        return entropy
    
    def _calculate_confidence_intervals(self, probabilities: Dict[str, float]) -> Dict[str, Tuple[float, float]]:
        """Calculate confidence intervals"""
        posterior = probabilities.get('posterior', 0.5)
        
        # Mock confidence interval
        margin = 0.1
        lower = max(0.0, posterior - margin)
        upper = min(1.0, posterior + margin)
        
        return {
            'posterior_95_ci': (lower, upper)
        }
    
    def _classify_probabilistic_query(self, query: str) -> str:
        """Classify type of probabilistic query"""
        if 'given' in query:
            return 'conditional_probability'
        elif 'cause' in query:
            return 'causal_inference'
        elif 'predict' in query:
            return 'prediction'
        else:
            return 'marginal_probability'
    
    def _build_causal_graph(self, relationships: List[Dict]) -> Dict[str, List[str]]:
        """Build causal graph from relationships"""
        graph = defaultdict(list)
        
        for rel in relationships:
            graph[rel['cause']].append(rel['effect'])
        
        return dict(graph)

class TemporalReasoner(ReasoningEngine):
    """Temporal reasoning engine for time-based inference"""
    
    def __init__(self, name: str = "TemporalReasoner"):
        super().__init__(name)
        self.temporal_facts = []
        self.temporal_intervals = {}
        
    def reason(self, query: Any, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Perform temporal reasoning"""
        
        temporal_query = self._parse_temporal_query(query)
        
        # Interval algebra reasoning
        interval_relations = self._interval_reasoning(temporal_query)
        
        # Temporal logic inference
        temporal_inference = self._temporal_logic_inference(temporal_query)
        
        # Event sequence analysis
        sequence_analysis = self._analyze_event_sequences(temporal_query)
        
        return {
            'query': query,
            'temporal_form': temporal_query,
            'interval_relations': interval_relations,
            'temporal_inference': temporal_inference,
            'sequence_analysis': sequence_analysis,
            'timeline': self._construct_timeline(temporal_query)
        }
    
    def _parse_temporal_query(self, query: Any) -> Dict[str, Any]:
        """Parse temporal elements from query"""
        query_str = str(query).lower()
        
        # Extract temporal keywords
        temporal_keywords = ['before', 'after', 'during', 'while', 'when', 'since', 'until']
        found_keywords = [kw for kw in temporal_keywords if kw in query_str]
        
        # Extract time expressions
        time_expressions = self._extract_time_expressions(query_str)
        
        # Extract events
        events = self._extract_events(query_str)
        
        return {
            'temporal_keywords': found_keywords,
            'time_expressions': time_expressions,
            'events': events,
            'query_type': self._classify_temporal_query(query_str)
        }
    
    def _interval_reasoning(self, temporal_query: Dict[str, Any]) -> Dict[str, Any]:
        """Perform Allen's interval algebra reasoning"""
        
        events = temporal_query.get('events', [])
        
        if len(events) < 2:
            return {'relations': []}
        
        # Mock interval relations (would implement full Allen algebra)
        relations = []
        
        for i in range(len(events) - 1):
            event1 = events[i]
            event2 = events[i + 1]
            
            # Determine temporal relation
            relation = self._determine_interval_relation(event1, event2)
            relations.append({
                'event1': event1,
                'event2': event2,
                'relation': relation,
                'confidence': 0.8
            })
        
        return {
            'relations': relations,
            'consistency': self._check_temporal_consistency(relations)
        }
    
    def _temporal_logic_inference(self, temporal_query: Dict[str, Any]) -> Dict[str, Any]:
        """Perform temporal logic inference"""
        
        events = temporal_query.get('events', [])
        
        # Mock temporal logic reasoning
        temporal_rules = [
            {'rule': 'if A before B and B before C, then A before C', 'type': 'transitivity'},
            {'rule': 'if A during B, then A starts after B starts', 'type': 'containment'},
            {'rule': 'if A meets B, then A finishes when B starts', 'type': 'meeting'}
        ]
        
        applied_rules = []
        for event in events:
            for rule in temporal_rules:
                if np.random.random() > 0.7:  # Mock rule application
                    applied_rules.append({
                        'rule': rule,
                        'event': event,
                        'result': f'Applied {rule["type"]} to {event}'
                    })
        
        return {
            'applied_rules': applied_rules,
            'inferred_relations': self._infer_temporal_relations(applied_rules)
        }
    
    def _analyze_event_sequences(self, temporal_query: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze sequences of events"""
        
        events = temporal_query.get('events', [])
        
        if not events:
            return {'sequences': []}
        
        # Mock sequence analysis
        sequences = []
        
        # Simple sequential pattern
        if len(events) >= 2:
            sequences.append({
                'type': 'sequential',
                'events': events,
                'pattern': 'linear_sequence',
                'probability': 0.85
            })
        
        # Parallel pattern
        if len(events) >= 3:
            sequences.append({
                'type': 'parallel',
                'events': events[:2],
                'concurrent_with': events[2:],
                'pattern': 'concurrent_execution',
                'probability': 0.6
            })
        
        return {
            'sequences': sequences,
            'most_likely': max(sequences, key=lambda x: x['probability']) if sequences else None
        }
    
    def _extract_time_expressions(self, query: str) -> List[str]:
        """Extract time expressions from query"""
        
        time_patterns = ['yesterday', 'today', 'tomorrow', 'morning', 'evening', 'noon']
        found_expressions = []
        
        for pattern in time_patterns:
            if pattern in query:
                found_expressions.append(pattern)
        
        # Look for specific times (simplified)
        words = query.split()
        for word in words:
            if ':' in word or word.endswith('am') or word.endswith('pm'):
                found_expressions.append(word)
        
        return found_expressions
    
    def _extract_events(self, query: str) -> List[str]:
        """Extract events from query"""
        
        # Simplified event extraction
        action_words = ['start', 'finish', 'begin', 'end', 'occur', 'happen']
        events = []
        
        words = query.split()
        for i, word in enumerate(words):
            if word in action_words and i + 1 < len(words):
                events.append(f"{word}_{words[i + 1]}")
        
        return events
    
    def _classify_temporal_query(self, query: str) -> str:
        """Classify type of temporal query"""
        
        if 'when' in query:
            return 'temporal_location'
        elif 'before' in query or 'after' in query:
            return 'temporal_ordering'
        elif 'during' in query:
            return 'temporal_inclusion'
        elif 'how long' in query:
            return 'temporal_duration'
        else:
            return 'temporal_general'
    
    def _determine_interval_relation(self, event1: str, event2: str) -> str:
        """Determine Allen interval relation between events"""
        
        # Mock relation determination
        relations = ['before', 'meets', 'overlaps', 'starts', 'during', 'finishes', 'equal']
        return np.random.choice(relations)
    
    def _check_temporal_consistency(self, relations: List[Dict]) -> bool:
        """Check consistency of temporal relations"""
        # Simplified consistency check
        return len(relations) > 0 and all(rel['confidence'] > 0.5 for rel in relations)
    
    def _infer_temporal_relations(self, applied_rules: List[Dict]) -> List[str]:
        """Infer new temporal relations from rules"""
        
        inferred = []
        for rule_application in applied_rules:
            if rule_application['rule']['type'] == 'transitivity':
                inferred.append('transitive_relation_inferred')
            elif rule_application['rule']['type'] == 'containment':
                inferred.append('containment_relation_inferred')
        
        return inferred
    
    def _construct_timeline(self, temporal_query: Dict[str, Any]) -> Dict[str, Any]:
        """Construct timeline from temporal information"""
        
        events = temporal_query.get('events', [])
        time_expressions = temporal_query.get('time_expressions', [])
        
        timeline = {
            'events': [],
            'duration': 'unknown',
            'resolution': 'minutes'
        }
        
        for i, event in enumerate(events):
            timeline['events'].append({
                'event': event,
                'sequence_number': i + 1,
                'time': time_expressions[i] if i < len(time_expressions) else 'unspecified',
                'duration_estimate': np.random.randint(1, 60)  # Mock duration in minutes
            })
        
        return timeline
```

## Planning algorithms

### Classical planning

Traditional AI planning using symbolic representations and search:

```python
@dataclass
class State:
    """Represents a world state"""
    predicates: Set[str]  # Set of true predicates
    variables: Dict[str, Any] = field(default_factory=dict)
    
    def __hash__(self):
        return hash(frozenset(self.predicates))
    
    def __eq__(self, other):
        return isinstance(other, State) and self.predicates == other.predicates

@dataclass 
class Action:
    """Represents a planning action"""
    name: str
    parameters: List[str] = field(default_factory=list)
    preconditions: Set[str] = field(default_factory=set)
    add_effects: Set[str] = field(default_factory=set)  # What becomes true
    delete_effects: Set[str] = field(default_factory=set)  # What becomes false
    cost: float = 1.0
    
    def is_applicable(self, state: State) -> bool:
        """Check if action can be applied in given state"""
        return self.preconditions.issubset(state.predicates)
    
    def apply(self, state: State) -> State:
        """Apply action to state, returning new state"""
        if not self.is_applicable(state):
            raise ValueError(f"Action {self.name} not applicable in current state")
        
        new_predicates = state.predicates.copy()
        new_predicates.update(self.add_effects)
        new_predicates.difference_update(self.delete_effects)
        
        return State(predicates=new_predicates, variables=state.variables.copy())

@dataclass
class Goal:
    """Represents a planning goal"""
    predicates: Set[str]
    priority: float = 1.0
    deadline: Optional[float] = None
    
    def is_satisfied(self, state: State) -> bool:
        """Check if goal is satisfied in given state"""
        return self.predicates.issubset(state.predicates)
    
    def satisfaction_degree(self, state: State) -> float:
        """Calculate degree of goal satisfaction (0.0 to 1.0)"""
        if not self.predicates:
            return 1.0
        
        satisfied = len(self.predicates.intersection(state.predicates))
        total = len(self.predicates)
        return satisfied / total

class ClassicalPlanner:
    """Classical AI planner using forward and backward search"""
    
    def __init__(self, name: str = "ClassicalPlanner"):
        self.name = name
        self.actions = []
        self.domain_knowledge = {}
        
    def add_action(self, action: Action):
        """Add an action to the planner's action space"""
        self.actions.append(action)
    
    def plan(self, initial_state: State, goal: Goal, 
            max_depth: int = 20, search_strategy: str = "forward") -> Dict[str, Any]:
        """Generate a plan to achieve the goal"""
        
        if search_strategy == "forward":
            return self._forward_search(initial_state, goal, max_depth)
        elif search_strategy == "backward":
            return self._backward_search(initial_state, goal, max_depth)
        elif search_strategy == "bidirectional":
            return self._bidirectional_search(initial_state, goal, max_depth)
        else:
            raise ValueError(f"Unknown search strategy: {search_strategy}")
    
    def _forward_search(self, initial_state: State, goal: Goal, max_depth: int) -> Dict[str, Any]:
        """Forward search from initial state to goal"""
        
        frontier = [(0, initial_state, [])]  # (cost, state, path)
        explored = set()
        nodes_expanded = 0
        
        while frontier and nodes_expanded < 1000:  # Prevent infinite loops
            cost, current_state, path = heapq.heappop(frontier)
            nodes_expanded += 1
            
            if current_state in explored:
                continue
                
            explored.add(current_state)
            
            # Check if goal is satisfied
            if goal.is_satisfied(current_state):
                return {
                    'success': True,
                    'plan': path,
                    'cost': cost,
                    'nodes_expanded': nodes_expanded,
                    'final_state': current_state
                }
            
            # Don't search beyond max depth
            if len(path) >= max_depth:
                continue
            
            # Generate successor states
            for action in self.actions:
                if action.is_applicable(current_state):
                    next_state = action.apply(current_state)
                    if next_state not in explored:
                        new_cost = cost + action.cost
                        new_path = path + [action]
                        
                        # Add heuristic for A* search
                        heuristic = self._calculate_heuristic(next_state, goal)
                        priority = new_cost + heuristic
                        
                        heapq.heappush(frontier, (priority, next_state, new_path))
        
        return {
            'success': False,
            'reason': 'No plan found within search limits',
            'nodes_expanded': nodes_expanded
        }
    
    def _backward_search(self, initial_state: State, goal: Goal, max_depth: int) -> Dict[str, Any]:
        """Backward search from goal to initial state"""
        
        # Start with goal conditions
        goal_state = State(predicates=goal.predicates)
        frontier = [(0, goal_state, [])]  # (cost, state, path)
        explored = set()
        nodes_expanded = 0
        
        while frontier and nodes_expanded < 1000:
            cost, current_state, path = heapq.heappop(frontier)
            nodes_expanded += 1
            
            if current_state in explored:
                continue
                
            explored.add(current_state)
            
            # Check if we've reached the initial state
            if current_state.predicates.issubset(initial_state.predicates):
                # Reverse the path for forward execution
                forward_plan = list(reversed(path))
                return {
                    'success': True,
                    'plan': forward_plan,
                    'cost': cost,
                    'nodes_expanded': nodes_expanded,
                    'search_direction': 'backward'
                }
            
            if len(path) >= max_depth:
                continue
            
            # Find actions that could achieve current state
            for action in self.actions:
                if self._can_achieve_state(action, current_state):
                    # Create predecessor state
                    predecessor = self._create_predecessor_state(current_state, action)
                    
                    if predecessor not in explored:
                        new_cost = cost + action.cost
                        new_path = [action] + path
                        
                        heuristic = self._calculate_backward_heuristic(predecessor, initial_state)
                        priority = new_cost + heuristic
                        
                        heapq.heappush(frontier, (priority, predecessor, new_path))
        
        return {
            'success': False,
            'reason': 'No plan found with backward search',
            'nodes_expanded': nodes_expanded
        }
    
    def _calculate_heuristic(self, state: State, goal: Goal) -> float:
        """Calculate heuristic distance to goal (admissible)"""
        
        # Simple heuristic: number of unsatisfied goal predicates
        unsatisfied = goal.predicates - state.predicates
        return len(unsatisfied)
    
    def _calculate_backward_heuristic(self, state: State, initial_state: State) -> float:
        """Calculate heuristic distance to initial state"""
        
        # Number of predicates that don't match initial state
        difference = state.predicates.symmetric_difference(initial_state.predicates)
        return len(difference)
    
    def _can_achieve_state(self, action: Action, state: State) -> bool:
        """Check if action can help achieve the given state"""
        
        # Action can achieve state if its add effects intersect with state predicates
        return bool(action.add_effects.intersection(state.predicates))
    
    def _create_predecessor_state(self, state: State, action: Action) -> State:
        """Create predecessor state by inverting action effects"""
        
        predecessor_predicates = state.predicates.copy()
        
        # Remove add effects (they weren't true before)
        predecessor_predicates.difference_update(action.add_effects)
        
        # Add delete effects (they were true before)
        predecessor_predicates.update(action.delete_effects)
        
        # Add preconditions (they must have been true)
        predecessor_predicates.update(action.preconditions)
        
        return State(predicates=predecessor_predicates)
    
    def optimize_plan(self, plan: List[Action], initial_state: State) -> List[Action]:
        """Optimize plan by removing redundant actions"""
        
        if not plan:
            return plan
        
        optimized_plan = []
        current_state = initial_state
        
        for action in plan:
            # Check if action is still necessary
            if action.is_applicable(current_state):
                # Check if action effects are not already satisfied
                if not action.add_effects.issubset(current_state.predicates):
                    optimized_plan.append(action)
                    current_state = action.apply(current_state)
        
        return optimized_plan

class HierarchicalTaskNetwork(ClassicalPlanner):
    """Hierarchical Task Network (HTN) planner"""
    
    def __init__(self, name: str = "HTNPlanner"):
        super().__init__(name)
        self.methods = {}  # Task decomposition methods
        self.compound_tasks = set()
        self.primitive_tasks = set()
        
    def add_method(self, task: str, method_name: str, 
                  preconditions: Set[str], subtasks: List[str]):
        """Add a method for decomposing a compound task"""
        
        if task not in self.methods:
            self.methods[task] = []
        
        method = {
            'name': method_name,
            'preconditions': preconditions,
            'subtasks': subtasks
        }
        
        self.methods[task].append(method)
        self.compound_tasks.add(task)
    
    def plan_htn(self, initial_state: State, tasks: List[str], 
                max_depth: int = 50) -> Dict[str, Any]:
        """Plan using hierarchical task network"""
        
        plan, final_state, decomposition_tree = self._htn_search(
            tasks, initial_state, [], max_depth
        )
        
        if plan is not None:
            return {
                'success': True,
                'plan': plan,
                'final_state': final_state,
                'decomposition_tree': decomposition_tree,
                'task_hierarchy': self._analyze_task_hierarchy(decomposition_tree)
            }
        else:
            return {
                'success': False,
                'reason': 'No valid task decomposition found'
            }
    
    def _htn_search(self, tasks: List[str], state: State, 
                   current_plan: List[Action], depth: int) -> Tuple[Optional[List[Action]], State, Dict]:
        """Recursive HTN search"""
        
        if depth <= 0:
            return None, state, {}
        
        if not tasks:
            return current_plan, state, {'type': 'success', 'tasks': []}
        
        task = tasks[0]
        remaining_tasks = tasks[1:]
        
        decomposition_tree = {'task': task, 'decompositions': []}
        
        # If it's a primitive task, execute directly
        if task in self.primitive_tasks:
            # Find corresponding action
            action = self._find_action_for_task(task)
            if action and action.is_applicable(state):
                new_state = action.apply(state)
                new_plan = current_plan + [action]
                
                result_plan, final_state, sub_tree = self._htn_search(
                    remaining_tasks, new_state, new_plan, depth - 1
                )
                
                if result_plan is not None:
                    decomposition_tree['decompositions'].append({
                        'method': 'primitive',
                        'action': action,
                        'subtree': sub_tree
                    })
                    return result_plan, final_state, decomposition_tree
        
        # If it's a compound task, try all applicable methods
        elif task in self.methods:
            for method in self.methods[task]:
                if method['preconditions'].issubset(state.predicates):
                    # Try this method
                    new_tasks = method['subtasks'] + remaining_tasks
                    
                    result_plan, final_state, sub_tree = self._htn_search(
                        new_tasks, state, current_plan, depth - 1
                    )
                    
                    if result_plan is not None:
                        decomposition_tree['decompositions'].append({
                            'method': method['name'],
                            'subtasks': method['subtasks'],
                            'subtree': sub_tree
                        })
                        return result_plan, final_state, decomposition_tree
        
        return None, state, decomposition_tree
    
    def _find_action_for_task(self, task: str) -> Optional[Action]:
        """Find action corresponding to primitive task"""
        
        for action in self.actions:
            if action.name.lower() == task.lower():
                return action
        
        return None
    
    def _analyze_task_hierarchy(self, decomposition_tree: Dict) -> Dict[str, Any]:
        """Analyze the task hierarchy from decomposition tree"""
        
        def count_depth(tree, current_depth=0):
            if not tree.get('decompositions'):
                return current_depth
            
            max_depth = current_depth
            for decomp in tree['decompositions']:
                if 'subtree' in decomp:
                    depth = count_depth(decomp['subtree'], current_depth + 1)
                    max_depth = max(max_depth, depth)
            
            return max_depth
        
        def count_tasks(tree):
            task_count = 1  # Current task
            for decomp in tree.get('decompositions', []):
                if 'subtree' in decomp:
                    task_count += count_tasks(decomp['subtree'])
            return task_count
        
        return {
            'max_depth': count_depth(decomposition_tree),
            'total_tasks': count_tasks(decomposition_tree),
            'compound_tasks': len(self.compound_tasks),
            'primitive_tasks': len(self.primitive_tasks)
        }

class ProbabilisticPlanner(ClassicalPlanner):
    """Probabilistic planner handling uncertainty in actions and outcomes"""
    
    def __init__(self, name: str = "ProbabilisticPlanner"):
        super().__init__(name)
        self.action_probabilities = {}  # Action success probabilities
        self.state_probabilities = {}   # State probability distributions
        
    def add_probabilistic_action(self, action: Action, 
                                success_probability: float,
                                failure_effects: Set[str] = None):
        """Add action with success probability and failure effects"""
        
        self.add_action(action)
        self.action_probabilities[action.name] = {
            'success_prob': success_probability,
            'failure_effects': failure_effects or set()
        }
    
    def plan_with_uncertainty(self, initial_state: State, goal: Goal,
                            confidence_threshold: float = 0.8,
                            max_depth: int = 20) -> Dict[str, Any]:
        """Plan considering action uncertainty"""
        
        # Use value iteration / policy iteration approach
        policy, values = self._compute_optimal_policy(initial_state, goal, max_depth)
        
        # Extract plan from policy
        plan, expected_success = self._extract_plan_from_policy(
            policy, initial_state, goal
        )
        
        # Generate contingency plans
        contingency_plans = self._generate_contingency_plans(
            initial_state, goal, plan
        )
        
        return {
            'success': expected_success >= confidence_threshold,
            'plan': plan,
            'expected_success_probability': expected_success,
            'policy': policy,
            'value_function': values,
            'contingency_plans': contingency_plans,
            'confidence_threshold': confidence_threshold
        }
    
    def _compute_optimal_policy(self, initial_state: State, goal: Goal, 
                              max_depth: int) -> Tuple[Dict, Dict]:
        """Compute optimal policy using dynamic programming"""
        
        # Initialize value function
        values = defaultdict(float)
        policy = {}
        
        # Value iteration
        for iteration in range(max_depth):
            new_values = defaultdict(float)
            
            # Generate all reachable states (simplified)
            states = self._generate_reachable_states(initial_state, max_depth)
            
            for state in states:
                if goal.is_satisfied(state):
                    new_values[state] = 100.0  # High reward for goal
                    policy[state] = None  # No action needed
                else:
                    best_value = float('-inf')
                    best_action = None
                    
                    for action in self.actions:
                        if action.is_applicable(state):
                            expected_value = self._calculate_expected_value(
                                action, state, values
                            )
                            
                            if expected_value > best_value:
                                best_value = expected_value
                                best_action = action
                    
                    new_values[state] = best_value
                    policy[state] = best_action
            
            values = new_values
        
        return policy, values
    
    def _calculate_expected_value(self, action: Action, state: State, 
                                values: Dict) -> float:
        """Calculate expected value of taking action in state"""
        
        prob_info = self.action_probabilities.get(action.name, {
            'success_prob': 1.0,
            'failure_effects': set()
        })
        
        success_prob = prob_info['success_prob']
        failure_effects = prob_info['failure_effects']
        
        # Calculate value for success case
        success_state = action.apply(state)
        success_value = values.get(success_state, 0.0)
        
        # Calculate value for failure case
        failure_predicates = state.predicates.copy()
        failure_predicates.update(failure_effects)
        failure_state = State(predicates=failure_predicates)
        failure_value = values.get(failure_state, 0.0) - 10.0  # Penalty for failure
        
        # Expected value
        expected_value = (success_prob * success_value + 
                         (1 - success_prob) * failure_value - 
                         action.cost)
        
        return expected_value
    
    def _generate_reachable_states(self, initial_state: State, max_depth: int) -> Set[State]:
        """Generate set of reachable states (simplified)"""
        
        reachable = {initial_state}
        frontier = [initial_state]
        
        for depth in range(max_depth):
            new_frontier = []
            
            for state in frontier:
                for action in self.actions:
                    if action.is_applicable(state):
                        new_state = action.apply(state)
                        if new_state not in reachable:
                            reachable.add(new_state)
                            new_frontier.append(new_state)
            
            frontier = new_frontier
            if not frontier:
                break
        
        return reachable
    
    def _extract_plan_from_policy(self, policy: Dict, initial_state: State, 
                                goal: Goal) -> Tuple[List[Action], float]:
        """Extract plan from policy and calculate success probability"""
        
        plan = []
        current_state = initial_state
        success_probability = 1.0
        
        max_steps = 50  # Prevent infinite loops
        steps = 0
        
        while not goal.is_satisfied(current_state) and steps < max_steps:
            action = policy.get(current_state)
            
            if action is None:
                break
            
            plan.append(action)
            
            # Update success probability
            action_prob = self.action_probabilities.get(action.name, {
                'success_prob': 1.0
            })['success_prob']
            
            success_probability *= action_prob
            
            # Move to next state (assume success for plan extraction)
            current_state = action.apply(current_state)
            steps += 1
        
        return plan, success_probability
    
    def _generate_contingency_plans(self, initial_state: State, goal: Goal,
                                  main_plan: List[Action]) -> List[Dict]:
        """Generate contingency plans for action failures"""
        
        contingency_plans = []
        current_state = initial_state
        
        for i, action in enumerate(main_plan):
            # What if this action fails?
            prob_info = self.action_probabilities.get(action.name, {})
            failure_effects = prob_info.get('failure_effects', set())
            
            if failure_effects:
                # Create failure state
                failure_state = State(
                    predicates=current_state.predicates.union(failure_effects)
                )
                
                # Plan recovery from failure state
                recovery_plan = self.plan(failure_state, goal, max_depth=10)
                
                if recovery_plan['success']:
                    contingency_plans.append({
                        'trigger_step': i,
                        'failed_action': action.name,
                        'failure_state': failure_state,
                        'recovery_plan': recovery_plan['plan'],
                        'recovery_cost': recovery_plan['cost']
                    })
            
            # Assume success for next iteration
            current_state = action.apply(current_state)
        
        return contingency_plans

# Integration with EderSpark for scientific reasoning and planning
class ScientificReasoningAgent:
    """Scientific reasoning agent using EderSpark's Freiya platform"""
    
    def __init__(self, api_key: str = ""):
        self.api_key = api_key
        self.symbolic_reasoner = SymbolicReasoner("ScientificSymbolic")
        self.probabilistic_reasoner = ProbabilisticReasoner("ScientificProbabilistic")
        self.temporal_reasoner = TemporalReasoner("ScientificTemporal")
        self.planner = HierarchicalTaskNetwork("ScientificPlanner")
        
        self._initialize_scientific_knowledge()
        self._setup_research_planning()
        
    def _initialize_scientific_knowledge(self):
        """Initialize scientific reasoning rules and knowledge"""
        
        # Add scientific reasoning rules
        hypothesis_rule = Rule(
            premises=[
                Fact("observation", ["X"]),
                Fact("pattern", ["X", "Y"])
            ],
            conclusion=Fact("hypothesis", ["Y"]),
            rule_type="abductive_inference"
        )
        
        self.symbolic_reasoner.add_rule(hypothesis_rule)
        
        # Add scientific beliefs
        scientific_method_belief = Belief(
            content="Scientific method requires hypothesis testing",
            confidence=0.95,
            source="scientific_methodology",
            timestamp=time.time(),
            knowledge_type=KnowledgeType.PROCEDURAL
        )
        
        self.symbolic_reasoner.add_belief(scientific_method_belief)
    
    def _setup_research_planning(self):
        """Setup research planning tasks and methods"""
        
        # Add compound research tasks
        self.planner.add_method(
            task="conduct_literature_review",
            method_name="systematic_review",
            preconditions={"research_question_defined"},
            subtasks=["search_literature", "screen_papers", "extract_data", "synthesize_findings"]
        )
        
        self.planner.add_method(
            task="design_experiment",
            method_name="controlled_experiment",
            preconditions={"hypothesis_formulated"},
            subtasks=["define_variables", "design_protocol", "plan_data_collection", "validate_design"]
        )
        
        # Add primitive research actions
        research_actions = [
            Action(
                name="search_literature",
                preconditions={"research_question_defined"},
                add_effects={"literature_search_completed"},
                cost=2.0
            ),
            Action(
                name="formulate_hypothesis",
                preconditions={"literature_review_completed"},
                add_effects={"hypothesis_formulated"},
                cost=3.0
            ),
            Action(
                name="design_protocol",
                preconditions={"hypothesis_formulated", "variables_defined"},
                add_effects={"protocol_designed"},
                cost=4.0
            )
        ]
        
        for action in research_actions:
            self.planner.add_action(action)
            self.planner.primitive_tasks.add(action.name)
    
    def reason_about_scientific_query(self, query: str, 
                                    reasoning_types: List[ReasoningType] = None) -> Dict[str, Any]:
        """Perform multi-modal reasoning about scientific query"""
        
        if reasoning_types is None:
            reasoning_types = [ReasoningType.SYMBOLIC, ReasoningType.PROBABILISTIC, ReasoningType.TEMPORAL]
        
        results = {
            'query': query,
            'reasoning_results': {},
            'integrated_conclusion': {},
            'confidence': 0.0
        }
        
        # Apply different reasoning modes
        if ReasoningType.DEDUCTIVE in reasoning_types or ReasoningType.SYMBOLIC in reasoning_types:
            symbolic_result = self.symbolic_reasoner.reason(query)
            results['reasoning_results']['symbolic'] = symbolic_result
        
        if ReasoningType.PROBABILISTIC in reasoning_types:
            probabilistic_result = self.probabilistic_reasoner.reason(query)
            results['reasoning_results']['probabilistic'] = probabilistic_result
        
        if ReasoningType.TEMPORAL in reasoning_types:
            temporal_result = self.temporal_reasoner.reason(query)
            results['reasoning_results']['temporal'] = temporal_result
        
        # Integrate reasoning results
        results['integrated_conclusion'] = self._integrate_reasoning_results(
            results['reasoning_results']
        )
        
        results['confidence'] = self._calculate_integrated_confidence(
            results['reasoning_results']
        )
        
        return results
    
    def plan_research_project(self, research_question: str, 
                            available_resources: Dict[str, Any]) -> Dict[str, Any]:
        """Plan a scientific research project"""
        
        # Define initial state
        initial_predicates = {
            "research_question_defined",
            f"budget_available_{available_resources.get('budget', 'limited')}",
            f"time_available_{available_resources.get('time_months', 12)}_months"
        }
        
        if available_resources.get('lab_access', False):
            initial_predicates.add("lab_access_available")
        
        initial_state = State(predicates=initial_predicates)
        
        # Define research goals
        research_tasks = ["conduct_literature_review", "design_experiment", "collect_data", "analyze_results"]
        
        # Generate research plan
        plan_result = self.planner.plan_htn(initial_state, research_tasks)
        
        if plan_result['success']:
            # Estimate timeline and resources
            timeline = self._estimate_research_timeline(plan_result['plan'])
            resource_requirements = self._estimate_resource_requirements(plan_result['plan'])
            
            return {
                'success': True,
                'research_plan': plan_result['plan'],
                'task_hierarchy': plan_result['task_hierarchy'],
                'estimated_timeline': timeline,
                'resource_requirements': resource_requirements,
                'risk_assessment': self._assess_research_risks(plan_result['plan'])
            }
        else:
            return {
                'success': False,
                'reason': plan_result['reason'],
                'recommendations': self._generate_planning_recommendations(
                    research_question, available_resources
                )
            }
    
    def _integrate_reasoning_results(self, reasoning_results: Dict[str, Any]) -> Dict[str, Any]:
        """Integrate results from different reasoning modes"""
        
        integrated = {
            'conclusions': [],
            'evidence': [],
            'uncertainties': [],
            'recommendations': []
        }
        
        # Combine conclusions from different reasoners
        for reasoning_type, result in reasoning_results.items():
            if 'conclusion' in result:
                integrated['conclusions'].extend(result['conclusion'])
            
            if 'confidence' in result and result['confidence'] < 0.7:
                integrated['uncertainties'].append({
                    'source': reasoning_type,
                    'confidence': result['confidence'],
                    'details': result
                })
        
        # Generate integrated recommendations
        if len(integrated['uncertainties']) > 0:
            integrated['recommendations'].append(
                "Consider gathering additional evidence to reduce uncertainties"
            )
        
        if len(integrated['conclusions']) > 3:
            integrated['recommendations'].append(
                "Multiple lines of evidence support the conclusions"
            )
        
        return integrated
    
    def _calculate_integrated_confidence(self, reasoning_results: Dict[str, Any]) -> float:
        """Calculate integrated confidence from multiple reasoning modes"""
        
        confidences = []
        
        for reasoning_type, result in reasoning_results.items():
            if 'confidence' in result:
                confidences.append(result['confidence'])
        
        if not confidences:
            return 0.5
        
        # Use weighted average with higher weight for agreement
        mean_confidence = np.mean(confidences)
        agreement = 1.0 - np.std(confidences)  # Higher std = lower agreement
        
        integrated_confidence = mean_confidence * (0.7 + 0.3 * agreement)
        
        return min(1.0, integrated_confidence)
    
    def _estimate_research_timeline(self, plan: List[Action]) -> Dict[str, Any]:
        """Estimate timeline for research plan"""
        
        # Mock timeline estimation
        total_weeks = sum(action.cost for action in plan) * 2
        
        return {
            'total_weeks': total_weeks,
            'phases': [
                {'phase': 'Literature Review', 'weeks': total_weeks * 0.3},
                {'phase': 'Experiment Design', 'weeks': total_weeks * 0.2},
                {'phase': 'Data Collection', 'weeks': total_weeks * 0.3},
                {'phase': 'Analysis & Writing', 'weeks': total_weeks * 0.2}
            ],
            'critical_path': [action.name for action in plan[:3]]
        }
    
    def _estimate_resource_requirements(self, plan: List[Action]) -> Dict[str, Any]:
        """Estimate resource requirements for research plan"""
        
        return {
            'personnel': {
                'principal_investigator': 1,
                'research_assistants': len(plan) // 3,
                'technicians': 1 if any('experiment' in action.name for action in plan) else 0
            },
            'equipment': {
                'computers': 2,
                'lab_equipment': 'experiment' in str([action.name for action in plan]),
                'software_licenses': ['statistical_software', 'reference_manager']
            },
            'budget_estimate': {
                'personnel': len(plan) * 5000,
                'equipment': 15000 if 'experiment' in str(plan) else 5000,
                'materials': len(plan) * 1000,
                'total': len(plan) * 6000 + 15000
            }
        }
    
    def _assess_research_risks(self, plan: List[Action]) -> List[Dict[str, Any]]:
        """Assess risks in the research plan"""
        
        risks = []
        
        if len(plan) > 8:
            risks.append({
                'risk': 'Project complexity',
                'probability': 0.6,
                'impact': 'high',
                'mitigation': 'Break project into smaller phases'
            })
        
        if any('experiment' in action.name for action in plan):
            risks.append({
                'risk': 'Experimental failure',
                'probability': 0.4,
                'impact': 'medium',
                'mitigation': 'Design pilot studies and have backup protocols'
            })
        
        risks.append({
            'risk': 'Timeline overrun',
            'probability': 0.7,
            'impact': 'medium',
            'mitigation': 'Build in buffer time and regular milestone reviews'
        })
        
        return risks
    
    def _generate_planning_recommendations(self, research_question: str, 
                                        resources: Dict[str, Any]) -> List[str]:
        """Generate recommendations when planning fails"""
        
        recommendations = []
        
        if resources.get('budget', 0) < 50000:
            recommendations.append("Consider seeking additional funding for comprehensive research")
        
        if resources.get('time_months', 12) < 6:
            recommendations.append("Research timeline may be too short - consider extending or reducing scope")
        
        if not resources.get('lab_access', False):
            recommendations.append("Consider computational or theoretical approaches if lab access is limited")
        
        return recommendations

def main():
    """Example usage of reasoning and planning systems"""
    
    print("Agent Reasoning and Planning Demo")
    print("=" * 50)
    
    # Test symbolic reasoning
    symbolic_reasoner = SymbolicReasoner()
    
    # Add some facts and rules
    fact1 = Fact("bird", ["tweety"])
    fact2 = Fact("flies", ["tweety"])
    belief1 = Belief(content=fact1, confidence=0.9, source="observation", timestamp=time.time())
    symbolic_reasoner.add_belief(belief1)
    
    rule1 = Rule(
        premises=[Fact("bird", ["X"])],
        conclusion=Fact("has_wings", ["X"]),
        rule_type="taxonomic"
    )
    symbolic_reasoner.add_rule(rule1)
    
    # Test reasoning
    reasoning_result = symbolic_reasoner.reason("Does tweety have wings?")
    print(f"Symbolic Reasoning Result: {reasoning_result['conclusion']}")
    
    # Test probabilistic reasoning
    prob_reasoner = ProbabilisticReasoner()
    prob_result = prob_reasoner.reason("What is the probability of rain given dark clouds?")
    print(f"Probabilistic Reasoning: {prob_result['posterior_probabilities']}")
    
    # Test classical planning
    planner = ClassicalPlanner()
    
    # Define actions for simple blocks world
    pickup_action = Action(
        name="pickup",
        parameters=["block"],
        preconditions={"clear_block", "hand_empty"},
        add_effects={"holding_block"},
        delete_effects={"clear_block", "hand_empty"}
    )
    
    putdown_action = Action(
        name="putdown",
        parameters=["block"],
        preconditions={"holding_block"},
        add_effects={"clear_block", "hand_empty"},
        delete_effects={"holding_block"}
    )
    
    planner.add_action(pickup_action)
    planner.add_action(putdown_action)
    
    # Define problem
    initial_state = State(predicates={"clear_block", "hand_empty", "block_on_table"})
    goal = Goal(predicates={"holding_block"})
    
    # Plan
    plan_result = planner.plan(initial_state, goal)
    if plan_result['success']:
        print(f"Classical Planning: Found plan with {len(plan_result['plan'])} actions")
        for i, action in enumerate(plan_result['plan']):
            print(f"  Step {i+1}: {action.name}")
    
    # Test scientific reasoning agent
    scientific_agent = ScientificReasoningAgent()
    
    # Test scientific reasoning
    scientific_query = "What factors influence protein folding stability?"
    sci_result = scientific_agent.reason_about_scientific_query(scientific_query)
    print(f"\nScientific Reasoning Confidence: {sci_result['confidence']:.2f}")
    
    # Test research planning
    research_question = "How do machine learning models perform on scientific literature analysis?"
    resources = {
        'budget': 100000,
        'time_months': 18,
        'lab_access': True
    }
    
    research_plan = scientific_agent.plan_research_project(research_question, resources)
    if research_plan['success']:
        print(f"Research Planning: {len(research_plan['research_plan'])} planned actions")
        print(f"Estimated timeline: {research_plan['estimated_timeline']['total_weeks']} weeks")
    
    return symbolic_reasoner, prob_reasoner, planner, scientific_agent

if __name__ == "__main__":
    symbolic_reasoner, prob_reasoner, planner, scientific_agent = main()
```

This comprehensive guide to agent reasoning and planning provides the theoretical foundations and practical implementations needed to build intelligent agents capable of sophisticated cognitive processes. From symbolic logic and probabilistic inference to hierarchical planning and scientific reasoning, these systems enable agents to understand complex situations, make informed decisions, and pursue long-term goals effectively.

The integration with EderSpark's Freiya platform demonstrates how these reasoning and planning capabilities can be applied to real-world scientific research, enabling agents to conduct literature reviews, formulate hypotheses, design experiments, and plan comprehensive research projects with proper resource allocation and risk assessment.