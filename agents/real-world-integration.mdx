---
title: "AI Agent Real-World Integration"
description: "Comprehensive guide to integrating AI agents into real-world systems, covering deployment patterns, production considerations, monitoring, security, and scalability for enterprise and research environments."
---

# AI Agent Real-World Integration

Real-world integration represents the culmination of AI agent development, where theoretical capabilities meet practical deployment challenges. This comprehensive guide explores the complete journey from laboratory prototypes to production-ready agent systems, covering deployment architectures, operational considerations, monitoring strategies, security frameworks, and scalability patterns that enable successful agent integration in enterprise and research environments.

## Production Deployment Architecture

### Agent System Architecture

A production-ready agent system requires sophisticated architecture that balances performance, reliability, scalability, and maintainability while providing the operational visibility necessary for enterprise deployment.

```python
import asyncio
import logging
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Callable, Type
from dataclasses import dataclass, field
from enum import Enum
import json
import time
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
import aioredis
import asyncpg
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import kubernetes
from kubernetes import client, config
import docker
import yaml

class DeploymentEnvironment(Enum):
    """Deployment environment types"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    RESEARCH = "research"

class AgentStatus(Enum):
    """Agent operational status"""
    INITIALIZING = "initializing"
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    TERMINATED = "terminated"

@dataclass
class AgentConfiguration:
    """Agent configuration for deployment"""
    agent_id: str
    agent_type: str
    environment: DeploymentEnvironment
    resource_limits: Dict[str, Any]
    dependencies: List[str]
    health_check_config: Dict[str, Any]
    monitoring_config: Dict[str, Any]
    security_config: Dict[str, Any]
    scaling_config: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert configuration to dictionary"""
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type,
            "environment": self.environment.value,
            "resource_limits": self.resource_limits,
            "dependencies": self.dependencies,
            "health_check_config": self.health_check_config,
            "monitoring_config": self.monitoring_config,
            "security_config": self.security_config,
            "scaling_config": self.scaling_config
        }

class MetricsCollector:
    """Centralized metrics collection for agent systems"""
    
    def __init__(self):
        # Prometheus metrics
        self.request_count = Counter('agent_requests_total', 
                                   'Total number of agent requests',
                                   ['agent_id', 'agent_type', 'status'])
        
        self.request_duration = Histogram('agent_request_duration_seconds',
                                        'Agent request duration in seconds',
                                        ['agent_id', 'agent_type'])
        
        self.active_agents = Gauge('agent_active_count',
                                 'Number of active agents',
                                 ['agent_type', 'environment'])
        
        self.function_calls = Counter('agent_function_calls_total',
                                    'Total number of function calls',
                                    ['agent_id', 'function_name', 'status'])
        
        self.resource_usage = Gauge('agent_resource_usage',
                                  'Agent resource usage',
                                  ['agent_id', 'resource_type'])
        
        self.error_count = Counter('agent_errors_total',
                                 'Total number of agent errors',
                                 ['agent_id', 'error_type'])
    
    def record_request(self, agent_id: str, agent_type: str, 
                      duration: float, status: str):
        """Record agent request metrics"""
        self.request_count.labels(
            agent_id=agent_id, 
            agent_type=agent_type, 
            status=status
        ).inc()
        
        self.request_duration.labels(
            agent_id=agent_id,
            agent_type=agent_type
        ).observe(duration)
    
    def update_active_agents(self, agent_type: str, environment: str, count: int):
        """Update active agent count"""
        self.active_agents.labels(
            agent_type=agent_type,
            environment=environment
        ).set(count)
    
    def record_function_call(self, agent_id: str, function_name: str, status: str):
        """Record function call metrics"""
        self.function_calls.labels(
            agent_id=agent_id,
            function_name=function_name,
            status=status
        ).inc()
    
    def update_resource_usage(self, agent_id: str, cpu_usage: float, 
                            memory_usage: float):
        """Update resource usage metrics"""
        self.resource_usage.labels(
            agent_id=agent_id,
            resource_type="cpu"
        ).set(cpu_usage)
        
        self.resource_usage.labels(
            agent_id=agent_id,
            resource_type="memory"
        ).set(memory_usage)
    
    def record_error(self, agent_id: str, error_type: str):
        """Record error metrics"""
        self.error_count.labels(
            agent_id=agent_id,
            error_type=error_type
        ).inc()

class HealthChecker:
    """Health checking system for agents"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics = metrics_collector
        self.health_checks: Dict[str, Callable] = {}
        self.check_intervals: Dict[str, int] = {}
        self.check_results: Dict[str, Dict] = {}
        self._running = False
    
    def register_health_check(self, name: str, check_func: Callable, 
                            interval: int = 30):
        """Register a health check function"""
        self.health_checks[name] = check_func
        self.check_intervals[name] = interval
        self.check_results[name] = {
            "status": "unknown",
            "last_check": None,
            "message": "",
            "check_count": 0,
            "failure_count": 0
        }
    
    async def start_health_monitoring(self):
        """Start health monitoring loop"""
        self._running = True
        
        # Create tasks for each health check
        tasks = []
        for name in self.health_checks:
            task = asyncio.create_task(self._run_health_check_loop(name))
            tasks.append(task)
        
        # Wait for all tasks
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _run_health_check_loop(self, check_name: str):
        """Run individual health check loop"""
        while self._running:
            try:
                check_func = self.health_checks[check_name]
                interval = self.check_intervals[check_name]
                
                # Run health check
                start_time = time.time()
                result = await check_func()
                duration = time.time() - start_time
                
                # Update results
                self.check_results[check_name].update({
                    "status": "healthy" if result.get("healthy", False) else "unhealthy",
                    "last_check": datetime.now().isoformat(),
                    "message": result.get("message", ""),
                    "check_count": self.check_results[check_name]["check_count"] + 1,
                    "duration": duration
                })
                
                if not result.get("healthy", False):
                    self.check_results[check_name]["failure_count"] += 1
                
                # Wait for next check
                await asyncio.sleep(interval)
                
            except Exception as e:
                logging.error(f"Health check {check_name} failed: {e}")
                self.check_results[check_name].update({
                    "status": "error",
                    "last_check": datetime.now().isoformat(),
                    "message": f"Check error: {str(e)}",
                    "failure_count": self.check_results[check_name]["failure_count"] + 1
                })
                await asyncio.sleep(30)  # Wait before retrying
    
    def get_overall_health(self) -> Dict[str, Any]:
        """Get overall system health status"""
        overall_status = "healthy"
        unhealthy_checks = []
        
        for name, result in self.check_results.items():
            if result["status"] in ["unhealthy", "error"]:
                overall_status = "unhealthy"
                unhealthy_checks.append(name)
            elif result["status"] == "unknown" and overall_status == "healthy":
                overall_status = "unknown"
        
        return {
            "overall_status": overall_status,
            "unhealthy_checks": unhealthy_checks,
            "check_details": self.check_results.copy(),
            "last_updated": datetime.now().isoformat()
        }
    
    def stop(self):
        """Stop health monitoring"""
        self._running = False

class ProductionAgent(ABC):
    """Base class for production-ready agents"""
    
    def __init__(self, config: AgentConfiguration, 
                 metrics: MetricsCollector, 
                 health_checker: HealthChecker):
        self.config = config
        self.metrics = metrics
        self.health_checker = health_checker
        self.status = AgentStatus.INITIALIZING
        self.start_time = datetime.now()
        self.last_activity = datetime.now()
        self.request_count = 0
        self.error_count = 0
        self.logger = logging.getLogger(f"agent.{config.agent_id}")
        
        # Register health checks
        self._setup_health_checks()
    
    def _setup_health_checks(self):
        """Setup agent health checks"""
        self.health_checker.register_health_check(
            f"{self.config.agent_id}_basic",
            self._basic_health_check,
            interval=30
        )
        
        self.health_checker.register_health_check(
            f"{self.config.agent_id}_resource",
            self._resource_health_check,
            interval=60
        )
        
        self.health_checker.register_health_check(
            f"{self.config.agent_id}_functional",
            self._functional_health_check,
            interval=120
        )
    
    async def _basic_health_check(self) -> Dict[str, Any]:
        """Basic health check - agent responsiveness"""
        try:
            # Check if agent is responsive
            current_time = datetime.now()
            time_since_activity = (current_time - self.last_activity).total_seconds()
            
            # Consider unhealthy if no activity for 5 minutes
            if time_since_activity > 300:
                return {
                    "healthy": False,
                    "message": f"No activity for {time_since_activity:.0f} seconds"
                }
            
            return {
                "healthy": True,
                "message": f"Agent responsive, last activity {time_since_activity:.0f}s ago"
            }
            
        except Exception as e:
            return {
                "healthy": False,
                "message": f"Basic health check failed: {str(e)}"
            }
    
    async def _resource_health_check(self) -> Dict[str, Any]:
        """Resource health check - CPU, memory usage"""
        try:
            import psutil
            
            # Get current process
            process = psutil.Process()
            
            # Check CPU usage
            cpu_percent = process.cpu_percent()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            # Update metrics
            self.metrics.update_resource_usage(
                self.config.agent_id, 
                cpu_percent, 
                memory_mb
            )
            
            # Check against limits
            cpu_limit = self.config.resource_limits.get("cpu_limit", 80)
            memory_limit = self.config.resource_limits.get("memory_limit_mb", 1024)
            
            if cpu_percent > cpu_limit:
                return {
                    "healthy": False,
                    "message": f"High CPU usage: {cpu_percent:.1f}% (limit: {cpu_limit}%)"
                }
            
            if memory_mb > memory_limit:
                return {
                    "healthy": False,
                    "message": f"High memory usage: {memory_mb:.1f}MB (limit: {memory_limit}MB)"
                }
            
            return {
                "healthy": True,
                "message": f"CPU: {cpu_percent:.1f}%, Memory: {memory_mb:.1f}MB"
            }
            
        except Exception as e:
            return {
                "healthy": False,
                "message": f"Resource health check failed: {str(e)}"
            }
    
    async def _functional_health_check(self) -> Dict[str, Any]:
        """Functional health check - agent-specific functionality"""
        try:
            # This should be implemented by specific agent types
            return await self.perform_functional_health_check()
        except Exception as e:
            return {
                "healthy": False,
                "message": f"Functional health check failed: {str(e)}"
            }
    
    @abstractmethod
    async def perform_functional_health_check(self) -> Dict[str, Any]:
        """Perform agent-specific functional health check"""
        pass
    
    @abstractmethod
    async def initialize(self):
        """Initialize the agent"""
        pass
    
    @abstractmethod
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Process a request"""
        pass
    
    async def start(self):
        """Start the agent"""
        try:
            self.logger.info(f"Starting agent {self.config.agent_id}")
            
            # Initialize agent
            await self.initialize()
            
            # Update status
            self.status = AgentStatus.HEALTHY
            
            # Update metrics
            self.metrics.update_active_agents(
                self.config.agent_type,
                self.config.environment.value,
                1
            )
            
            self.logger.info(f"Agent {self.config.agent_id} started successfully")
            
        except Exception as e:
            self.status = AgentStatus.UNHEALTHY
            self.metrics.record_error(self.config.agent_id, "initialization_error")
            self.logger.error(f"Failed to start agent {self.config.agent_id}: {e}")
            raise
    
    async def handle_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle a request with monitoring and error handling"""
        start_time = time.time()
        status = "success"
        
        try:
            self.request_count += 1
            self.last_activity = datetime.now()
            
            # Process the request
            response = await self.process_request(request)
            
            return response
            
        except Exception as e:
            status = "error"
            self.error_count += 1
            self.metrics.record_error(self.config.agent_id, "request_error")
            
            # Log error
            self.logger.error(f"Request processing failed: {e}")
            
            return {
                "success": False,
                "error": str(e),
                "agent_id": self.config.agent_id
            }
            
        finally:
            # Record metrics
            duration = time.time() - start_time
            self.metrics.record_request(
                self.config.agent_id,
                self.config.agent_type,
                duration,
                status
            )
    
    async def stop(self):
        """Stop the agent gracefully"""
        self.logger.info(f"Stopping agent {self.config.agent_id}")
        self.status = AgentStatus.TERMINATED
        
        # Update metrics
        self.metrics.update_active_agents(
            self.config.agent_type,
            self.config.environment.value,
            0
        )
```

### Container Orchestration

Modern AI agent deployment relies heavily on containerization and orchestration platforms like Kubernetes for scalability, reliability, and management.

```python
class KubernetesDeploymentManager:
    """Manages Kubernetes deployments for AI agents"""
    
    def __init__(self, namespace: str = "ai-agents"):
        self.namespace = namespace
        self.k8s_client = None
        self.apps_v1 = None
        self.core_v1 = None
        self._setup_kubernetes_client()
    
    def _setup_kubernetes_client(self):
        """Setup Kubernetes client"""
        try:
            # Try to load in-cluster config first
            config.load_incluster_config()
        except:
            # Fallback to local kubeconfig
            config.load_kube_config()
        
        self.k8s_client = client.ApiClient()
        self.apps_v1 = client.AppsV1Api()
        self.core_v1 = client.CoreV1Api()
    
    async def deploy_agent(self, agent_config: AgentConfiguration, 
                          image: str, replicas: int = 1) -> Dict[str, Any]:
        """Deploy agent to Kubernetes"""
        try:
            # Create deployment manifest
            deployment = self._create_deployment_manifest(
                agent_config, image, replicas
            )
            
            # Create service manifest
            service = self._create_service_manifest(agent_config)
            
            # Apply deployment
            self.apps_v1.create_namespaced_deployment(
                namespace=self.namespace,
                body=deployment
            )
            
            # Apply service
            self.core_v1.create_namespaced_service(
                namespace=self.namespace,
                body=service
            )
            
            return {
                "success": True,
                "deployment_name": f"{agent_config.agent_id}-deployment",
                "service_name": f"{agent_config.agent_id}-service",
                "namespace": self.namespace
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_deployment_manifest(self, agent_config: AgentConfiguration, 
                                  image: str, replicas: int) -> Dict[str, Any]:
        """Create Kubernetes deployment manifest"""
        return {
            "apiVersion": "apps/v1",
            "kind": "Deployment",
            "metadata": {
                "name": f"{agent_config.agent_id}-deployment",
                "labels": {
                    "app": agent_config.agent_id,
                    "agent-type": agent_config.agent_type,
                    "environment": agent_config.environment.value
                }
            },
            "spec": {
                "replicas": replicas,
                "selector": {
                    "matchLabels": {
                        "app": agent_config.agent_id
                    }
                },
                "template": {
                    "metadata": {
                        "labels": {
                            "app": agent_config.agent_id,
                            "agent-type": agent_config.agent_type,
                            "environment": agent_config.environment.value
                        }
                    },
                    "spec": {
                        "containers": [{
                            "name": agent_config.agent_id,
                            "image": image,
                            "ports": [{
                                "containerPort": 8080,
                                "name": "http"
                            }],
                            "env": [
                                {
                                    "name": "AGENT_ID",
                                    "value": agent_config.agent_id
                                },
                                {
                                    "name": "AGENT_TYPE", 
                                    "value": agent_config.agent_type
                                },
                                {
                                    "name": "ENVIRONMENT",
                                    "value": agent_config.environment.value
                                }
                            ],
                            "resources": {
                                "limits": {
                                    "cpu": agent_config.resource_limits.get("cpu", "1"),
                                    "memory": agent_config.resource_limits.get("memory", "1Gi")
                                },
                                "requests": {
                                    "cpu": agent_config.resource_limits.get("cpu_request", "0.5"),
                                    "memory": agent_config.resource_limits.get("memory_request", "512Mi")
                                }
                            },
                            "livenessProbe": {
                                "httpGet": {
                                    "path": "/health",
                                    "port": 8080
                                },
                                "initialDelaySeconds": 30,
                                "periodSeconds": 30
                            },
                            "readinessProbe": {
                                "httpGet": {
                                    "path": "/ready",
                                    "port": 8080
                                },
                                "initialDelaySeconds": 10,
                                "periodSeconds": 10
                            }
                        }]
                    }
                }
            }
        }
    
    def _create_service_manifest(self, agent_config: AgentConfiguration) -> Dict[str, Any]:
        """Create Kubernetes service manifest"""
        return {
            "apiVersion": "v1",
            "kind": "Service",
            "metadata": {
                "name": f"{agent_config.agent_id}-service",
                "labels": {
                    "app": agent_config.agent_id,
                    "agent-type": agent_config.agent_type
                }
            },
            "spec": {
                "selector": {
                    "app": agent_config.agent_id
                },
                "ports": [{
                    "port": 80,
                    "targetPort": 8080,
                    "name": "http"
                }],
                "type": "ClusterIP"
            }
        }
    
    async def scale_agent(self, agent_id: str, replicas: int) -> Dict[str, Any]:
        """Scale agent deployment"""
        try:
            deployment_name = f"{agent_id}-deployment"
            
            # Get current deployment
            deployment = self.apps_v1.read_namespaced_deployment(
                name=deployment_name,
                namespace=self.namespace
            )
            
            # Update replica count
            deployment.spec.replicas = replicas
            
            # Apply update
            self.apps_v1.patch_namespaced_deployment(
                name=deployment_name,
                namespace=self.namespace,
                body=deployment
            )
            
            return {
                "success": True,
                "message": f"Scaled {agent_id} to {replicas} replicas"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_agent_status(self, agent_id: str) -> Dict[str, Any]:
        """Get agent deployment status"""
        try:
            deployment_name = f"{agent_id}-deployment"
            
            # Get deployment
            deployment = self.apps_v1.read_namespaced_deployment(
                name=deployment_name,
                namespace=self.namespace
            )
            
            # Get pods
            pods = self.core_v1.list_namespaced_pod(
                namespace=self.namespace,
                label_selector=f"app={agent_id}"
            )
            
            pod_statuses = []
            for pod in pods.items:
                pod_statuses.append({
                    "name": pod.metadata.name,
                    "phase": pod.status.phase,
                    "ready": self._is_pod_ready(pod),
                    "restart_count": sum(
                        container.restart_count or 0 
                        for container in pod.status.container_statuses or []
                    )
                })
            
            return {
                "success": True,
                "deployment_name": deployment_name,
                "desired_replicas": deployment.spec.replicas,
                "ready_replicas": deployment.status.ready_replicas or 0,
                "available_replicas": deployment.status.available_replicas or 0,
                "pods": pod_statuses
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _is_pod_ready(self, pod) -> bool:
        """Check if pod is ready"""
        if not pod.status.conditions:
            return False
        
        for condition in pod.status.conditions:
            if condition.type == "Ready":
                return condition.status == "True"
        
        return False

class DockerDeploymentManager:
    """Manages Docker deployments for development and smaller scale deployments"""
    
    def __init__(self):
        self.docker_client = docker.from_env()
        self.running_containers: Dict[str, Any] = {}
    
    async def deploy_agent(self, agent_config: AgentConfiguration, 
                          image: str) -> Dict[str, Any]:
        """Deploy agent as Docker container"""
        try:
            container_name = f"{agent_config.agent_id}-container"
            
            # Environment variables
            environment = {
                "AGENT_ID": agent_config.agent_id,
                "AGENT_TYPE": agent_config.agent_type,
                "ENVIRONMENT": agent_config.environment.value
            }
            
            # Resource limits
            mem_limit = agent_config.resource_limits.get("memory", "1g")
            cpu_limit = agent_config.resource_limits.get("cpu", "1.0")
            
            # Create and start container
            container = self.docker_client.containers.run(
                image=image,
                name=container_name,
                environment=environment,
                mem_limit=mem_limit,
                cpu_quota=int(float(cpu_limit) * 100000),
                cpu_period=100000,
                ports={"8080/tcp": None},  # Random host port
                detach=True,
                restart_policy={"Name": "unless-stopped"}
            )
            
            # Store container info
            self.running_containers[agent_config.agent_id] = {
                "container": container,
                "config": agent_config
            }
            
            # Get assigned port
            container.reload()
            host_port = container.attrs["NetworkSettings"]["Ports"]["8080/tcp"][0]["HostPort"]
            
            return {
                "success": True,
                "container_id": container.id,
                "container_name": container_name,
                "host_port": host_port
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    async def stop_agent(self, agent_id: str) -> Dict[str, Any]:
        """Stop agent container"""
        try:
            if agent_id in self.running_containers:
                container = self.running_containers[agent_id]["container"]
                container.stop(timeout=30)
                container.remove()
                
                del self.running_containers[agent_id]
                
                return {
                    "success": True,
                    "message": f"Agent {agent_id} stopped and removed"
                }
            else:
                return {
                    "success": False,
                    "error": f"Agent {agent_id} not found"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_agent_logs(self, agent_id: str, tail: int = 100) -> Dict[str, Any]:
        """Get agent container logs"""
        try:
            if agent_id in self.running_containers:
                container = self.running_containers[agent_id]["container"]
                logs = container.logs(tail=tail).decode('utf-8')
                
                return {
                    "success": True,
                    "logs": logs
                }
            else:
                return {
                    "success": False,
                    "error": f"Agent {agent_id} not found"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
```

## Security and Authentication

### Security Framework

Production AI agents require comprehensive security frameworks that address authentication, authorization, data protection, and threat mitigation across all system components.

```python
import jwt
import bcrypt
import secrets
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import hashlib
from datetime import datetime, timedelta

class SecurityManager:
    """Comprehensive security management for AI agents"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.jwt_secret = config.get("jwt_secret", secrets.token_urlsafe(32))
        self.encryption_key = self._derive_encryption_key(config.get("master_key", ""))
        self.cipher_suite = Fernet(self.encryption_key)
        self.session_store = {}
        self.audit_log = []
        
        # Security policies
        self.password_policy = {
            "min_length": 12,
            "require_uppercase": True,
            "require_lowercase": True,
            "require_numbers": True,
            "require_special": True
        }
        
        self.rate_limits = {
            "login_attempts": {"limit": 5, "window": 300},  # 5 attempts per 5 minutes
            "api_calls": {"limit": 1000, "window": 3600},   # 1000 calls per hour
            "function_calls": {"limit": 100, "window": 60}   # 100 calls per minute
        }
        
        self.attempt_tracker = {}
    
    def _derive_encryption_key(self, master_key: str) -> bytes:
        """Derive encryption key from master key"""
        if not master_key:
            return Fernet.generate_key()
        
        # Derive key using PBKDF2
        salt = b"agent_security_salt"  # In production, use random salt per deployment
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        key = base64.urlsafe_b64encode(kdf.derive(master_key.encode()))
        return key
    
    def hash_password(self, password: str) -> str:
        """Hash password using bcrypt"""
        salt = bcrypt.gensalt()
        hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
        return hashed.decode('utf-8')
    
    def verify_password(self, password: str, hashed: str) -> bool:
        """Verify password against hash"""
        return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))
    
    def validate_password_policy(self, password: str) -> tuple[bool, List[str]]:
        """Validate password against security policy"""
        errors = []
        
        if len(password) < self.password_policy["min_length"]:
            errors.append(f"Password must be at least {self.password_policy['min_length']} characters")
        
        if self.password_policy["require_uppercase"] and not any(c.isupper() for c in password):
            errors.append("Password must contain at least one uppercase letter")
        
        if self.password_policy["require_lowercase"] and not any(c.islower() for c in password):
            errors.append("Password must contain at least one lowercase letter")
        
        if self.password_policy["require_numbers"] and not any(c.isdigit() for c in password):
            errors.append("Password must contain at least one number")
        
        if self.password_policy["require_special"]:
            special_chars = "!@#$%^&*()_+-=[]{}|;:,.<>?"
            if not any(c in special_chars for c in password):
                errors.append("Password must contain at least one special character")
        
        return len(errors) == 0, errors
    
    def generate_jwt_token(self, user_id: str, agent_id: str, 
                          roles: List[str], expires_in: int = 3600) -> str:
        """Generate JWT token for authentication"""
        payload = {
            "user_id": user_id,
            "agent_id": agent_id,
            "roles": roles,
            "iat": datetime.utcnow(),
            "exp": datetime.utcnow() + timedelta(seconds=expires_in),
            "jti": secrets.token_urlsafe(16)  # JWT ID for revocation
        }
        
        token = jwt.encode(payload, self.jwt_secret, algorithm="HS256")
        
        # Store token info for tracking
        self.session_store[payload["jti"]] = {
            "user_id": user_id,
            "agent_id": agent_id,
            "created_at": datetime.utcnow(),
            "expires_at": payload["exp"],
            "active": True
        }
        
        return token
    
    def verify_jwt_token(self, token: str) -> Dict[str, Any]:
        """Verify JWT token and return payload"""
        try:
            payload = jwt.decode(token, self.jwt_secret, algorithms=["HS256"])
            
            # Check if token is revoked
            jti = payload.get("jti")
            if jti in self.session_store:
                session = self.session_store[jti]
                if not session["active"]:
                    return {"valid": False, "error": "Token revoked"}
            
            return {"valid": True, "payload": payload}
            
        except jwt.ExpiredSignatureError:
            return {"valid": False, "error": "Token expired"}
        except jwt.InvalidTokenError:
            return {"valid": False, "error": "Invalid token"}
    
    def revoke_token(self, token: str) -> bool:
        """Revoke a JWT token"""
        try:
            payload = jwt.decode(token, self.jwt_secret, algorithms=["HS256"])
            jti = payload.get("jti")
            
            if jti in self.session_store:
                self.session_store[jti]["active"] = False
                return True
            
            return False
            
        except jwt.InvalidTokenError:
            return False
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """Encrypt sensitive data"""
        return self.cipher_suite.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """Decrypt sensitive data"""
        return self.cipher_suite.decrypt(encrypted_data.encode()).decode()
    
    def check_rate_limit(self, identifier: str, action: str) -> tuple[bool, Dict[str, Any]]:
        """Check if action is within rate limits"""
        if action not in self.rate_limits:
            return True, {"allowed": True}
        
        limit_config = self.rate_limits[action]
        current_time = time.time()
        window_start = current_time - limit_config["window"]
        
        # Initialize tracking for identifier/action
        key = f"{identifier}:{action}"
        if key not in self.attempt_tracker:
            self.attempt_tracker[key] = []
        
        # Remove old attempts outside the window
        self.attempt_tracker[key] = [
            timestamp for timestamp in self.attempt_tracker[key]
            if timestamp > window_start
        ]
        
        # Check if limit exceeded
        current_attempts = len(self.attempt_tracker[key])
        if current_attempts >= limit_config["limit"]:
            return False, {
                "allowed": False,
                "current_attempts": current_attempts,
                "limit": limit_config["limit"],
                "window_seconds": limit_config["window"],
                "reset_time": window_start + limit_config["window"]
            }
        
        # Record current attempt
        self.attempt_tracker[key].append(current_time)
        
        return True, {
            "allowed": True,
            "current_attempts": current_attempts + 1,
            "limit": limit_config["limit"],
            "remaining": limit_config["limit"] - current_attempts - 1
        }
    
    def log_security_event(self, event_type: str, user_id: str, 
                          agent_id: str, details: Dict[str, Any]):
        """Log security events for audit purposes"""
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "agent_id": agent_id,
            "details": details,
            "source_ip": details.get("source_ip", "unknown")
        }
        
        self.audit_log.append(event)
        
        # In production, this would be sent to a secure audit log system
        logging.info(f"Security event: {event_type} - User: {user_id} - Agent: {agent_id}")
    
    def validate_api_permissions(self, token_payload: Dict[str, Any], 
                                required_permissions: List[str]) -> bool:
        """Validate that token has required API permissions"""
        user_roles = token_payload.get("roles", [])
        
        # Define role permissions
        role_permissions = {
            "admin": ["*"],  # Admin has all permissions
            "agent_operator": ["agent:read", "agent:execute", "agent:monitor"],
            "researcher": ["agent:read", "agent:execute", "research:access"],
            "viewer": ["agent:read", "monitor:read"]
        }
        
        # Check if user has required permissions
        for role in user_roles:
            permissions = role_permissions.get(role, [])
            
            # Check for wildcard permission
            if "*" in permissions:
                return True
            
            # Check specific permissions
            for required_perm in required_permissions:
                if required_perm in permissions:
                    return True
        
        return False

class SecureAgent(ProductionAgent):
    """Production agent with integrated security features"""
    
    def __init__(self, config: AgentConfiguration, 
                 metrics: MetricsCollector,
                 health_checker: HealthChecker,
                 security_manager: SecurityManager):
        super().__init__(config, metrics, health_checker)
        self.security = security_manager
        self.secure_function_registry = {}
        self.access_log = []
    
    async def authenticate_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Authenticate incoming request"""
        auth_header = request.get("headers", {}).get("Authorization", "")
        
        if not auth_header.startswith("Bearer "):
            return {"authenticated": False, "error": "Missing or invalid authorization header"}
        
        token = auth_header[7:]  # Remove "Bearer " prefix
        
        # Verify token
        token_result = self.security.verify_jwt_token(token)
        if not token_result["valid"]:
            self.security.log_security_event(
                "authentication_failure",
                "unknown",
                self.config.agent_id,
                {"error": token_result["error"], "source_ip": request.get("source_ip", "unknown")}
            )
            return {"authenticated": False, "error": token_result["error"]}
        
        payload = token_result["payload"]
        
        # Check rate limits
        user_id = payload["user_id"]
        allowed, rate_info = self.security.check_rate_limit(user_id, "api_calls")
        
        if not allowed:
            self.security.log_security_event(
                "rate_limit_exceeded",
                user_id,
                self.config.agent_id,
                {"action": "api_calls", "rate_info": rate_info}
            )
            return {"authenticated": False, "error": "Rate limit exceeded"}
        
        # Log successful authentication
        self.security.log_security_event(
            "authentication_success",
            user_id,
            self.config.agent_id,
            {"source_ip": request.get("source_ip", "unknown")}
        )
        
        return {
            "authenticated": True,
            "user_id": user_id,
            "agent_id": payload["agent_id"],
            "roles": payload["roles"],
            "rate_info": rate_info
        }
    
    async def authorize_function_call(self, auth_info: Dict[str, Any], 
                                    function_name: str) -> bool:
        """Authorize function call based on user permissions"""
        
        # Check function-specific permissions
        required_permissions = self.secure_function_registry.get(
            function_name, ["agent:execute"]
        )
        
        if not self.security.validate_api_permissions(auth_info, required_permissions):
            self.security.log_security_event(
                "authorization_failure",
                auth_info["user_id"],
                self.config.agent_id,
                {"function": function_name, "required_permissions": required_permissions}
            )
            return False
        
        # Check function call rate limits
        allowed, rate_info = self.security.check_rate_limit(
            auth_info["user_id"], 
            "function_calls"
        )
        
        if not allowed:
            self.security.log_security_event(
                "rate_limit_exceeded",
                auth_info["user_id"],
                self.config.agent_id,
                {"action": "function_calls", "function": function_name}
            )
            return False
        
        return True
    
    def register_secure_function(self, function_name: str, 
                                required_permissions: List[str]):
        """Register function with required permissions"""
        self.secure_function_registry[function_name] = required_permissions
    
    async def handle_secure_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Handle request with security validation"""
        
        # Authenticate request
        auth_result = await self.authenticate_request(request)
        if not auth_result["authenticated"]:
            return {
                "success": False,
                "error": auth_result["error"],
                "error_type": "authentication_error"
            }
        
        # Extract function call if present
        function_name = request.get("function")
        if function_name:
            # Authorize function call
            if not await self.authorize_function_call(auth_result, function_name):
                return {
                    "success": False,
                    "error": "Insufficient permissions for function call",
                    "error_type": "authorization_error"
                }
        
        # Process request with security context
        secure_request = request.copy()
        secure_request["security_context"] = {
            "user_id": auth_result["user_id"],
            "roles": auth_result["roles"],
            "authenticated_at": datetime.utcnow().isoformat()
        }
        
        # Call parent handler
        response = await self.handle_request(secure_request)
        
        # Log access
        self.access_log.append({
            "timestamp": datetime.utcnow().isoformat(),
            "user_id": auth_result["user_id"],
            "function": function_name,
            "success": response.get("success", False),
            "source_ip": request.get("source_ip", "unknown")
        })
        
        return response
```

## EderSpark Scientific Agent Integration

### Freiya Platform Production Deployment

The integration with EderSpark's Freiya platform demonstrates real-world scientific AI agent deployment with enterprise-grade security, monitoring, and scalability.

```python
class FreiyaProductionAgent(SecureAgent):
    """Production-ready Freiya scientific research agent"""
    
    def __init__(self, config: AgentConfiguration,
                 metrics: MetricsCollector,
                 health_checker: HealthChecker,
                 security_manager: SecurityManager,
                 freiya_config: Dict[str, Any]):
        super().__init__(config, metrics, health_checker, security_manager)
        
        self.freiya_config = freiya_config
        self.freiya_api_key = security_manager.decrypt_sensitive_data(
            freiya_config["encrypted_api_key"]
        )
        self.workspace_id = freiya_config["workspace_id"]
        self.research_cache = {}
        self.collaboration_sessions = {}
        self.active_research_sessions = {}
        
        # Register secure functions with permissions
        self._register_freiya_functions()
        
        # Initialize Freiya client
        self.freiya_client = None
    
    def _register_freiya_functions(self):
        """Register Freiya functions with security permissions"""
        self.register_secure_function("search_papers", ["research:access", "agent:execute"])
        self.register_secure_function("analyze_citations", ["research:access", "analysis:execute"])
        self.register_secure_function("discover_collaborations", ["research:access", "collaboration:read"])
        self.register_secure_function("synthesize_literature", ["research:access", "synthesis:execute"])
        self.register_secure_function("identify_research_gaps", ["research:access", "analysis:execute"])
        self.register_secure_function("start_research_session", ["research:manage", "session:create"])
        self.register_secure_function("export_research_data", ["research:access", "data:export"])
    
    async def initialize(self):
        """Initialize Freiya agent"""
        try:
            # Initialize Freiya API client
            self.freiya_client = FreiyaAPIClient(
                api_key=self.freiya_api_key,
                workspace_id=self.workspace_id,
                base_url=self.freiya_config["api_base_url"]
            )
            
            # Test connection
            await self.freiya_client.health_check()
            
            self.logger.info("Freiya agent initialized successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize Freiya agent: {e}")
            raise
    
    async def perform_functional_health_check(self) -> Dict[str, Any]:
        """Perform Freiya-specific functional health check"""
        try:
            # Test Freiya API connectivity
            health_result = await self.freiya_client.health_check()
            
            if not health_result["healthy"]:
                return {
                    "healthy": False,
                    "message": f"Freiya API unhealthy: {health_result['message']}"
                }
            
            # Test basic search functionality
            test_result = await self.freiya_client.search(
                query="test query",
                max_results=1
            )
            
            if not test_result["success"]:
                return {
                    "healthy": False,
                    "message": f"Freiya search test failed: {test_result['error']}"
                }
            
            return {
                "healthy": True,
                "message": "Freiya agent functional check passed",
                "freiya_status": health_result["message"]
            }
            
        except Exception as e:
            return {
                "healthy": False,
                "message": f"Functional health check failed: {str(e)}"
            }
    
    async def process_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Process Freiya research requests"""
        function_name = request.get("function")
        parameters = request.get("parameters", {})
        security_context = request.get("security_context", {})
        
        try:
            if function_name == "search_papers":
                return await self._search_papers(parameters, security_context)
            
            elif function_name == "analyze_citations":
                return await self._analyze_citations(parameters, security_context)
            
            elif function_name == "discover_collaborations":
                return await self._discover_collaborations(parameters, security_context)
            
            elif function_name == "synthesize_literature":
                return await self._synthesize_literature(parameters, security_context)
            
            elif function_name == "identify_research_gaps":
                return await self._identify_research_gaps(parameters, security_context)
            
            elif function_name == "start_research_session":
                return await self._start_research_session(parameters, security_context)
            
            elif function_name == "export_research_data":
                return await self._export_research_data(parameters, security_context)
            
            else:
                return {
                    "success": False,
                    "error": f"Unknown function: {function_name}"
                }
                
        except Exception as e:
            self.logger.error(f"Error processing {function_name}: {e}")
            return {
                "success": False,
                "error": f"Function execution failed: {str(e)}"
            }
    
    async def _search_papers(self, params: Dict[str, Any], 
                           security_context: Dict[str, Any]) -> Dict[str, Any]:
        """Search scientific papers using Freiya"""
        query = params.get("query", "")
        max_results = params.get("max_results", 20)
        field_filter = params.get("field_filter")
        
        # Record function call metrics
        self.metrics.record_function_call(
            self.config.agent_id, 
            "search_papers", 
            "started"
        )
        
        try:
            # Execute search
            search_result = await self.freiya_client.search(
                query=query,
                max_results=max_results,
                field_filter=field_filter,
                user_context={
                    "user_id": security_context.get("user_id"),
                    "workspace_id": self.workspace_id
                }
            )
            
            if search_result["success"]:
                # Cache results for potential follow-up queries
                cache_key = hashlib.md5(
                    f"{query}_{max_results}_{field_filter}".encode()
                ).hexdigest()
                
                self.research_cache[cache_key] = {
                    "results": search_result["data"],
                    "query": query,
                    "timestamp": datetime.utcnow(),
                    "user_id": security_context.get("user_id")
                }
                
                # Record success metrics
                self.metrics.record_function_call(
                    self.config.agent_id,
                    "search_papers",
                    "success"
                )
                
                # Enhanced response with research insights
                enhanced_response = await self._enhance_search_response(
                    search_result["data"], query
                )
                
                return {
                    "success": True,
                    "data": enhanced_response,
                    "metadata": {
                        "query": query,
                        "results_count": len(search_result["data"].get("papers", [])),
                        "cache_key": cache_key,
                        "search_quality": search_result["data"].get("search_quality", "unknown")
                    }
                }
            else:
                # Record failure metrics
                self.metrics.record_function_call(
                    self.config.agent_id,
                    "search_papers", 
                    "failure"
                )
                
                return {
                    "success": False,
                    "error": search_result["error"]
                }
                
        except Exception as e:
            # Record error metrics
            self.metrics.record_function_call(
                self.config.agent_id,
                "search_papers",
                "error"
            )
            
            raise
    
    async def _enhance_search_response(self, search_data: Dict[str, Any], 
                                     query: str) -> Dict[str, Any]:
        """Enhance search response with additional insights"""
        enhanced = search_data.copy()
        
        papers = search_data.get("papers", [])
        if papers:
            # Calculate research metrics
            total_citations = sum(paper.get("citation_count", 0) for paper in papers)
            avg_citations = total_citations / len(papers)
            
            # Identify top-cited papers
            top_cited = sorted(papers, key=lambda p: p.get("citation_count", 0), reverse=True)[:5]
            
            # Analyze publication timeline
            publication_years = [
                int(paper.get("publication_date", "2000-01-01")[:4]) 
                for paper in papers 
                if paper.get("publication_date")
            ]
            
            year_distribution = {}
            for year in publication_years:
                year_distribution[year] = year_distribution.get(year, 0) + 1
            
            # Research insights
            enhanced["research_insights"] = {
                "total_papers": len(papers),
                "citation_metrics": {
                    "total_citations": total_citations,
                    "average_citations": round(avg_citations, 2),
                    "highly_cited_threshold": max(50, avg_citations * 2)
                },
                "top_cited_papers": top_cited,
                "publication_timeline": {
                    "year_distribution": year_distribution,
                    "most_active_year": max(year_distribution.items(), key=lambda x: x[1])[0] if year_distribution else None,
                    "recent_activity": sum(count for year, count in year_distribution.items() if year >= 2020)
                },
                "research_quality_score": min(100, (avg_citations / 20) * 100),  # Normalized quality score
                "research_velocity": "high" if len([y for y in publication_years if y >= 2022]) > len(papers) * 0.3 else "moderate"
            }
            
            # Identify research themes
            all_keywords = []
            for paper in papers:
                if "keywords" in paper:
                    all_keywords.extend(paper["keywords"])
            
            keyword_freq = {}
            for keyword in all_keywords:
                keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
            
            top_themes = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            
            enhanced["thematic_analysis"] = {
                "dominant_themes": [theme[0] for theme in top_themes],
                "theme_frequency": dict(top_themes),
                "research_breadth": len(set(all_keywords)),
                "theme_diversity_score": len(set(all_keywords)) / len(all_keywords) if all_keywords else 0
            }
        
        return enhanced
    
    async def _start_research_session(self, params: Dict[str, Any], 
                                    security_context: Dict[str, Any]) -> Dict[str, Any]:
        """Start a collaborative research session"""
        session_name = params.get("session_name", "")
        research_topic = params.get("research_topic", "")
        collaborators = params.get("collaborators", [])
        user_id = security_context.get("user_id")
        
        # Create session ID
        session_id = f"session_{int(time.time())}_{secrets.token_urlsafe(8)}"
        
        # Initialize research session
        session_data = {
            "session_id": session_id,
            "session_name": session_name,
            "research_topic": research_topic,
            "owner": user_id,
            "collaborators": collaborators,
            "created_at": datetime.utcnow(),
            "status": "active",
            "research_data": {},
            "shared_workspace": {},
            "activity_log": []
        }
        
        # Store session
        self.active_research_sessions[session_id] = session_data
        
        # Log session creation
        self.security.log_security_event(
            "research_session_created",
            user_id,
            self.config.agent_id,
            {
                "session_id": session_id,
                "session_name": session_name,
                "research_topic": research_topic,
                "collaborators": collaborators
            }
        )
        
        return {
            "success": True,
            "data": {
                "session_id": session_id,
                "session_name": session_name,
                "research_topic": research_topic,
                "status": "active",
                "collaborators": collaborators,
                "workspace_url": f"/research-sessions/{session_id}"
            },
            "message": "Research session started successfully"
        }

class FreiyaAPIClient:
    """Client for Freiya API with production features"""
    
    def __init__(self, api_key: str, workspace_id: str, base_url: str):
        self.api_key = api_key
        self.workspace_id = workspace_id
        self.base_url = base_url
        self.session = None
        self.request_timeout = 30
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=self.request_timeout),
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "X-Workspace-ID": self.workspace_id,
                "User-Agent": "EderSpark-Agent/2.0"
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def health_check(self) -> Dict[str, Any]:
        """Check Freiya API health"""
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(
                    f"{self.base_url}/health",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        return {
                            "healthy": True,
                            "message": "Freiya API is healthy",
                            "version": data.get("version", "unknown"),
                            "status": data.get("status", "unknown")
                        }
                    else:
                        return {
                            "healthy": False,
                            "message": f"Freiya API returned status {response.status}"
                        }
                        
            except Exception as e:
                return {
                    "healthy": False,
                    "message": f"Freiya API health check failed: {str(e)}"
                }
    
    async def search(self, query: str, max_results: int = 20, 
                    field_filter: str = None, user_context: Dict = None) -> Dict[str, Any]:
        """Search papers using Freiya API"""
        payload = {
            "query": query,
            "max_results": max_results,
            "include_semantic_analysis": True,
            "include_citation_context": True
        }
        
        if field_filter:
            payload["field_filter"] = field_filter
        
        if user_context:
            payload["user_context"] = user_context
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    f"{self.base_url}/search/semantic",
                    json=payload,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "X-Workspace-ID": self.workspace_id,
                        "Content-Type": "application/json"
                    },
                    timeout=aiohttp.ClientTimeout(total=self.request_timeout)
                ) as response:
                    
                    if response.status == 200:
                        data = await response.json()
                        return {
                            "success": True,
                            "data": data
                        }
                    else:
                        error_data = await response.json()
                        return {
                            "success": False,
                            "error": error_data.get("message", f"API error: {response.status}")
                        }
                        
            except asyncio.TimeoutError:
                return {
                    "success": False,
                    "error": "Request timeout - Freiya API did not respond in time"
                }
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Request failed: {str(e)}"
                }

# Demonstration of complete production deployment
async def demonstrate_production_deployment():
    """Demonstrate complete production deployment of Freiya agent"""
    
    print("Setting up Production AI Agent System...")
    
    # Initialize metrics and monitoring
    metrics = MetricsCollector()
    start_http_server(8000)  # Start Prometheus metrics server
    
    # Initialize health checker
    health_checker = HealthChecker(metrics)
    
    # Initialize security manager
    security_config = {
        "jwt_secret": secrets.token_urlsafe(32),
        "master_key": "production_master_key_2024"
    }
    security_manager = SecurityManager(security_config)
    
    # Configure Freiya agent
    agent_config = AgentConfiguration(
        agent_id="freiya_prod_001",
        agent_type="scientific_research",
        environment=DeploymentEnvironment.PRODUCTION,
        resource_limits={
            "cpu": "2",
            "memory": "4Gi",
            "cpu_request": "1",
            "memory_request": "2Gi",
            "cpu_limit": 80,
            "memory_limit_mb": 4096
        },
        dependencies=["freiya_api", "redis", "postgresql"],
        health_check_config={
            "basic_interval": 30,
            "resource_interval": 60,
            "functional_interval": 120
        },
        monitoring_config={
            "metrics_enabled": True,
            "audit_logging": True,
            "performance_tracking": True
        },
        security_config={
            "authentication_required": True,
            "rate_limiting_enabled": True,
            "audit_logging_enabled": True
        },
        scaling_config={
            "min_replicas": 2,
            "max_replicas": 10,
            "target_cpu_utilization": 70
        }
    )
    
    # Freiya configuration
    freiya_config = {
        "encrypted_api_key": security_manager.encrypt_sensitive_data("freiya_production_api_key"),
        "workspace_id": "ederspark_research_lab",
        "api_base_url": "https://api.freiya.ederspark.ai"
    }
    
    # Create production agent
    freiya_agent = FreiyaProductionAgent(
        config=agent_config,
        metrics=metrics,
        health_checker=health_checker,
        security_manager=security_manager,
        freiya_config=freiya_config
    )
    
    print(f"✓ Production agent configured: {agent_config.agent_id}")
    
    # Initialize deployment managers
    k8s_manager = KubernetesDeploymentManager(namespace="ai-agents")
    docker_manager = DockerDeploymentManager()
    
    print("✓ Deployment managers initialized")
    
    # Demonstrate agent startup
    try:
        await freiya_agent.start()
        print("✓ Freiya agent started successfully")
        
        # Start health monitoring
        health_task = asyncio.create_task(health_checker.start_health_monitoring())
        print("✓ Health monitoring started")
        
        # Simulate authenticated request
        print("\n" + "="*60)
        print("DEMONSTRATING SECURE REQUEST PROCESSING")
        print("="*60)
        
        # Create test JWT token
        test_token = security_manager.generate_jwt_token(
            user_id="researcher_001",
            agent_id="freiya_prod_001",
            roles=["researcher", "agent_operator"],
            expires_in=3600
        )
        
        # Simulate research request
        test_request = {
            "headers": {
                "Authorization": f"Bearer {test_token}"
            },
            "function": "search_papers",
            "parameters": {
                "query": "machine learning applications in climate change research",
                "max_results": 15,
                "field_filter": "environmental_science"
            },
            "source_ip": "192.168.1.100"
        }
        
        print("Processing research request...")
        response = await freiya_agent.handle_secure_request(test_request)
        
        if response.get("success"):
            print("✓ Research request processed successfully")
            data = response.get("data", {})
            insights = data.get("research_insights", {})
            
            print(f"  Papers found: {insights.get('total_papers', 0)}")
            print(f"  Average citations: {insights.get('citation_metrics', {}).get('average_citations', 0)}")
            print(f"  Research quality score: {insights.get('research_quality_score', 0):.1f}/100")
            
        else:
            print(f"✗ Research request failed: {response.get('error')}")
        
        # Demonstrate research session creation
        print("\nCreating collaborative research session...")
        session_request = {
            "headers": {
                "Authorization": f"Bearer {test_token}"
            },
            "function": "start_research_session",
            "parameters": {
                "session_name": "Climate AI Research Project",
                "research_topic": "AI applications in climate change mitigation",
                "collaborators": ["researcher_002", "researcher_003"]
            },
            "source_ip": "192.168.1.100"
        }
        
        session_response = await freiya_agent.handle_secure_request(session_request)
        
        if session_response.get("success"):
            print("✓ Research session created successfully")
            session_data = session_response.get("data", {})
            print(f"  Session ID: {session_data.get('session_id')}")
            print(f"  Workspace URL: {session_data.get('workspace_url')}")
        else:
            print(f"✗ Session creation failed: {session_response.get('error')}")
        
        # Show system health
        print("\n" + "="*60)
        print("SYSTEM HEALTH STATUS")
        print("="*60)
        
        overall_health = health_checker.get_overall_health()
        print(f"Overall Status: {overall_health['overall_status'].upper()}")
        
        for check_name, check_result in overall_health['check_details'].items():
            status = check_result['status']
            message = check_result.get('message', 'No message')
            print(f"  {check_name}: {status.upper()} - {message}")
        
        # Show security audit log
        print("\n" + "="*60)
        print("SECURITY AUDIT LOG (Recent Events)")
        print("="*60)
        
        recent_events = security_manager.audit_log[-5:]  # Last 5 events
        for event in recent_events:
            print(f"{event['timestamp']} | {event['event_type']} | User: {event['user_id']} | Agent: {event['agent_id']}")
        
        # Demonstrate deployment scaling (K8s simulation)
        print("\n" + "="*60)
        print("DEPLOYMENT SCALING SIMULATION")  
        print("="*60)
        
        # Simulate Kubernetes deployment
        deployment_result = await k8s_manager.deploy_agent(
            agent_config=agent_config,
            image="ederspark/freiya-agent:v2.0",
            replicas=2
        )
        
        if deployment_result["success"]:
            print("✓ Kubernetes deployment created")
            print(f"  Deployment: {deployment_result['deployment_name']}")
            print(f"  Service: {deployment_result['service_name']}")
            print(f"  Namespace: {deployment_result['namespace']}")
        
        # Simulate scaling
        scale_result = await k8s_manager.scale_agent(
            agent_id=agent_config.agent_id,
            replicas=5
        )
        
        if scale_result["success"]:
            print("✓ Agent scaled to 5 replicas")
        
    except Exception as e:
        print(f"✗ Production deployment failed: {e}")
    
    finally:
        # Cleanup
        await freiya_agent.stop()
        health_checker.stop()
        print("✓ Production system shutdown complete")

if __name__ == "__main__":
    asyncio.run(demonstrate_production_deployment())
```

## Conclusion

Real-world AI agent integration represents the ultimate test of agent system design, requiring careful consideration of production requirements, security frameworks, operational monitoring, and scalability patterns. The comprehensive implementation demonstrated in this guide provides a robust foundation for deploying AI agents in enterprise and research environments while maintaining the reliability, security, and performance characteristics necessary for mission-critical applications.

The deep integration with EderSpark's Freiya platform showcases how domain-specific AI agents can be successfully deployed in production environments, providing sophisticated research capabilities while adhering to enterprise security and operational standards. Through proper containerization, orchestration, monitoring, and security frameworks, AI agents can seamlessly integrate into existing enterprise infrastructure and deliver transformative capabilities to scientific research and discovery.

As AI agents continue to evolve and mature, the patterns and architectures presented in this guide establish a comprehensive blueprint for successful real-world deployment. The future of AI lies not just in the sophistication of individual agents, but in their ability to operate reliably, securely, and at scale within the complex ecosystem of modern enterprise and research environments.